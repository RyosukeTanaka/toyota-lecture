# ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢é€£ã®é–¢æ•°
import pandas as pd
import streamlit as st
import os
import numpy as np # numpyã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from typing import Optional, List, Dict, Tuple, Union # Dict, Tuple, Union ã‚’è¿½åŠ 
from .constants import PRICE_COLUMNS # å®šæ•°ã‚’ç›´æ¥å‚ç…§

@st.cache_data # Streamlitã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã‚’åˆ©ç”¨
def load_data(uploaded_file):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        uploaded_file.seek(0) # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
        df = pd.read_csv(uploaded_file)
        st.success("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        return df
    except pd.errors.EmptyDataError:
        st.error("ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™ã€‚")
        return None
    except Exception as e:
        st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# â˜…â˜…â˜… è¿”ã‚Šå€¤ã®å‹ãƒ’ãƒ³ãƒˆã¨ Docstring ã‚’å¤‰æ›´ â˜…â˜…â˜…
def recalculate_lag_feature(df_processed: pd.DataFrame, lag_target_col: str, lag_days: int, booking_date_col: str, group_cols: list) -> Tuple[pd.DataFrame, Optional[Dict[str, Union[str, int]]]]:
    """æŒ‡å®šã•ã‚ŒãŸåˆ—ã®ãƒ©ã‚°ç‰¹å¾´é‡ã‚’è¨ˆç®—ã—ã¦DataFrameã«è¿½åŠ ï¼ˆã¾ãŸã¯ä¸Šæ›¸ãï¼‰ã—ã€è¨ˆç®—çµæœæƒ…å ±ï¼ˆè¾æ›¸ï¼‰ã‚’è¿”ã™"""
    lag_col_name = f'{lag_target_col}_lag{lag_days}'
    result_info = None # è¨ˆç®—çµæœæƒ…å ±ç”¨

    required_lag_cols = group_cols + [booking_date_col, lag_target_col]
    if not all(col in df_processed.columns for col in required_lag_cols):
        missing = [col for col in required_lag_cols if col not in df_processed.columns]
        st.warning(f"ãƒ©ã‚°è¨ˆç®—è­¦å‘Š: å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä¸è¶³åˆ—: {missing}")
        if lag_col_name not in df_processed.columns: df_processed[lag_col_name] = np.nan
        return df_processed, None # â˜…â˜…â˜… ã‚¨ãƒ©ãƒ¼æ™‚ã¯ None ã‚’è¿”ã™ â˜…â˜…â˜…
    if not pd.api.types.is_datetime64_any_dtype(df_processed[booking_date_col]):
        st.warning(f"ãƒ©ã‚°è¨ˆç®—è­¦å‘Š: '{booking_date_col}' ãŒæ—¥ä»˜å‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        if lag_col_name not in df_processed.columns: df_processed[lag_col_name] = np.nan
        return df_processed, None
    if not pd.api.types.is_numeric_dtype(df_processed[lag_target_col]):
         try:
              df_processed[lag_target_col] = pd.to_numeric(df_processed[lag_target_col], errors='coerce')
              if df_processed[lag_target_col].isnull().all(): raise ValueError("å…¨ã¦NaN")
         except Exception:
              st.warning(f"ãƒ©ã‚°è¨ˆç®—è­¦å‘Š: '{lag_target_col}' ãŒæ•°å€¤å‹ã«å¤‰æ›ã§ãã¾ã›ã‚“ã€‚")
              if lag_col_name not in df_processed.columns: df_processed[lag_col_name] = np.nan
              return df_processed, None

    try:
        df_temp = df_processed[required_lag_cols].sort_values(by=group_cols + [booking_date_col])
        df_temp['booking_date_minus_lag'] = df_temp[booking_date_col] - pd.Timedelta(days=lag_days)
        df_lookup = df_temp[group_cols + [booking_date_col, lag_target_col]].rename(
            columns={lag_target_col: lag_col_name, booking_date_col: 'lookup_booking_date'}
        )
        df_merged = pd.merge(
            df_temp, df_lookup,
            left_on=group_cols + ['booking_date_minus_lag'],
            right_on=group_cols + ['lookup_booking_date'],
            how='left', suffixes=('', '_lookup')
        )
        df_processed[lag_col_name] = df_merged.set_index(df_temp.index)[lag_col_name]

        nan_count = df_processed[lag_col_name].isnull().sum()
        result_info = {"lag_col_name": lag_col_name, "nan_count": nan_count}

    except Exception as e:
        st.error(f"ãƒ©ã‚°ç‰¹å¾´é‡ '{lag_col_name}' ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        if lag_col_name not in df_processed.columns:
             df_processed[lag_col_name] = np.nan
        return df_processed, None # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ None ã‚’è¿”ã™

    return df_processed, result_info

def preprocess_data(df):
    """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆæ—¥ä»˜å¤‰æ›ã€ä¾¡æ ¼å·®è¨ˆç®—ãªã©ï¼‰ - ãƒ©ã‚°è¨ˆç®—ã¯å‰Šé™¤"""
    df_processed = df.copy()

    # --- æ—¥ä»˜é–¢é€£åˆ—ã®å¤‰æ› ---
    # 'åˆ©ç”¨æ—¥', 'äºˆç´„æ—¥' åˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã€å­˜åœ¨ã™ã‚Œã°datetimeå‹ã«å¤‰æ›
    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã‚’ç¶šã‘ã‚‹
    date_cols = ['åˆ©ç”¨æ—¥', 'äºˆç´„æ—¥']
    for col in date_cols:
        if col in df_processed.columns:
            try:
                df_processed[col] = pd.to_datetime(df_processed[col], errors='coerce')
            except Exception as e:
                st.warning(f"è­¦å‘Š: åˆ— '{col}' ã®æ—¥ä»˜å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        # else:
            # st.warning(f"è­¦å‘Š: æ—¥ä»˜å¤‰æ›å¯¾è±¡ã®åˆ— '{col}' ãŒãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # --- ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã®å†è¨ˆç®—ï¼ˆæ—¥ä»˜å¤‰æ›å¾Œï¼‰ ---
    # 'åˆ©ç”¨æ—¥' ã¨ 'äºˆç´„æ—¥' ãŒä¸¡æ–¹å­˜åœ¨ã—ã€datetimeå‹ã«å¤‰æ›æˆåŠŸã—ã¦ã„ã‚Œã°ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚’æ—¥æ•°ã§è¨ˆç®—
    if 'åˆ©ç”¨æ—¥' in df_processed.columns and 'äºˆç´„æ—¥' in df_processed.columns and \
       pd.api.types.is_datetime64_any_dtype(df_processed['åˆ©ç”¨æ—¥']) and \
       pd.api.types.is_datetime64_any_dtype(df_processed['äºˆç´„æ—¥']):
        try:
            # æ—¥ä»˜ã®å·®åˆ†ã‚’è¨ˆç®—ã—ã€æ—¥æ•°ï¼ˆæ•´æ•°ï¼‰ã¨ã—ã¦å–å¾—
            df_processed['ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ _è¨ˆç®—æ¸ˆ'] = (df_processed['åˆ©ç”¨æ—¥'] - df_processed['äºˆç´„æ—¥']).dt.days
            # å…ƒã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ åˆ—ãŒã‚ã‚Œã°ã€æ¯”è¼ƒã®ãŸã‚ã«æ®‹ã—ã¦ãŠãã‹ã€ã“ã“ã§å‰Šé™¤ã™ã‚‹ã‹é¸æŠ
            # if 'ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ' in df_processed.columns:
            #     st.write("å…ƒã® 'ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ' åˆ—ã¨è¨ˆç®—çµæœ 'ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ _è¨ˆç®—æ¸ˆ' ã‚’æ¯”è¼ƒã§ãã¾ã™ã€‚")
        except Exception as e:
            st.warning(f"è­¦å‘Š: ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if 'ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ' in df_processed.columns:
                 df_processed['ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ _è¨ˆç®—æ¸ˆ'] = df_processed['ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ '] # å…ƒã®åˆ—ã‚’ä½¿ã†
            # else:
                 # st.warning("è­¦å‘Š: ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚’è¨ˆç®—ã§ããšã€å…ƒã®åˆ—ã‚‚å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")


    # --- ä¾¡æ ¼å·®ç‰¹å¾´é‡ã®è¨ˆç®— ---
    # 'ä¾¡æ ¼_ãƒˆãƒ¨ã‚¿', 'ä¾¡æ ¼_ã‚ªãƒªãƒƒã‚¯ã‚¹' åˆ—ãŒå­˜åœ¨ã—ã€æ•°å€¤å‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    # price_cols = ['ä¾¡æ ¼_ãƒˆãƒ¨ã‚¿', 'ä¾¡æ ¼_ã‚ªãƒªãƒƒã‚¯ã‚¹'] # constantsã‹ã‚‰èª­ã¿è¾¼ã‚€ã‚ˆã†ã«å¤‰æ›´

    if len(PRICE_COLUMNS) >= 2 and all(col in df_processed.columns for col in PRICE_COLUMNS[:2]): # å…ˆé ­2åˆ—ã§è¨ˆç®—
        # æ•°å€¤å‹ã«å¤‰æ›è©¦è¡Œ (å¤‰æ›ã§ããªã„å€¤ã¯NaNã«ãªã‚‹)
        for col in PRICE_COLUMNS[:2]:
            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')

        # NaNãŒç™ºç”Ÿã—ãŸå ´åˆã®è­¦å‘Š
        if df_processed[PRICE_COLUMNS[:2]].isnull().any().any():
             st.warning(f"è­¦å‘Š: '{PRICE_COLUMNS[0]}', '{PRICE_COLUMNS[1]}' åˆ—ã«æ•°å€¤å¤‰æ›ã§ããªã„å€¤ã€ã¾ãŸã¯æ¬ æå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ä¾¡æ ¼å·®è¨ˆç®—ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

        # ã‚ˆã‚Šé ‘å¥ãªè¨ˆç®—ï¼ˆæ¬ æå€¤ãŒã‚ã£ã¦ã‚‚è¨ˆç®—ã§ãã‚‹ã‚ˆã†ã«ï¼‰
        df_processed['ä¾¡æ ¼å·®'] = df_processed[PRICE_COLUMNS[0]].sub(df_processed[PRICE_COLUMNS[1]], fill_value=None) # fill_value=Noneã§ç‰‡æ–¹NaNãªã‚‰çµæœã‚‚NaN
        # ä¾¡æ ¼æ¯”ï¼ˆã‚ªãƒªãƒƒã‚¯ã‚¹ãŒ0ã¾ãŸã¯NaNã®å ´åˆã¯NaNã«ã™ã‚‹ï¼‰
        denominator = df_processed[PRICE_COLUMNS[1]].replace(0, pd.NA)
        df_processed['ä¾¡æ ¼æ¯”'] = df_processed[PRICE_COLUMNS[0]].div(denominator, fill_value=None)

    elif len(PRICE_COLUMNS) == 1 and PRICE_COLUMNS[0] in df_processed.columns:
        st.info(f"ä¾¡æ ¼é–¢é€£ç‰¹å¾´é‡: '{PRICE_COLUMNS[0]}' ã®ã¿ãŒPRICE_COLUMNSã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ä¾¡æ ¼å·®ãƒ»ä¾¡æ ¼æ¯”ã¯è¨ˆç®—ã•ã‚Œã¾ã›ã‚“ã€‚")
        # å¿…è¦ã§ã‚ã‚Œã°ã€ä¾¡æ ¼å·®ã¨ä¾¡æ ¼æ¯”ã®åˆ—ã‚’NaNã§ä½œæˆ
        if 'ä¾¡æ ¼å·®' not in df_processed.columns:
            df_processed['ä¾¡æ ¼å·®'] = pd.NA
        if 'ä¾¡æ ¼æ¯”' not in df_processed.columns:
            df_processed['ä¾¡æ ¼æ¯”'] = pd.NA
    else:
        st.warning(f"è­¦å‘Š: ä¾¡æ ¼å·®è¨ˆç®—ã«å¿…è¦ãªåˆ— ({ ', '.join(PRICE_COLUMNS) if PRICE_COLUMNS else 'ãªã—'}) ãŒãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã¦ã„ãªã„ã‹ã€PRICE_COLUMNSã®è¨­å®šãŒä¸ååˆ†ã§ã™ã€‚ä¾¡æ ¼å·®ãƒ»ä¾¡æ ¼æ¯”ã¯è¨ˆç®—ã•ã‚Œã¾ã›ã‚“ã€‚")
        if 'ä¾¡æ ¼å·®' not in df_processed.columns:
            df_processed['ä¾¡æ ¼å·®'] = pd.NA
        if 'ä¾¡æ ¼æ¯”' not in df_processed.columns:
            df_processed['ä¾¡æ ¼æ¯”'] = pd.NA

    # --- ä¾¡æ ¼æ¯”è¨ˆç®—ã®å¾Œã«è¿½åŠ  ---
    st.success("ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆæ—¥ä»˜å¤‰æ›ã€ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ å†è¨ˆç®—ã€ä¾¡æ ¼å·®è¨ˆç®—ï¼‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ãƒ©ã‚°ç‰¹å¾´é‡è¨ˆç®—ã¯åˆ¥é€”å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚")

    return df_processed


def generate_exploration_report(df):
    """ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§ç”Ÿæˆã™ã‚‹"""
    markdown_report = []
    markdown_report.append("# ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ãƒ¬ãƒãƒ¼ãƒˆ")
    markdown_report.append("\n---\n")

    # åŸºæœ¬æƒ…å ±
    shape_info = f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ (è¡Œæ•°, åˆ—æ•°): {df.shape}"
    markdown_report.append("## åŸºæœ¬æƒ…å ±")
    markdown_report.append(shape_info)
    markdown_report.append("\n")

    # ãƒ‡ãƒ¼ã‚¿å‹
    dtypes_df = df.dtypes.reset_index().rename(columns={'index': 'åˆ—å', 0: 'ãƒ‡ãƒ¼ã‚¿å‹'})
    markdown_report.append("## ãƒ‡ãƒ¼ã‚¿å‹")
    markdown_report.append(dtypes_df.to_markdown(index=False))
    markdown_report.append("\n")

    # æ¬ æå€¤ã®æ•°
    missing_values = df.isnull().sum()
    missing_df = missing_values[missing_values > 0].reset_index().rename(columns={'index': 'åˆ—å', 0: 'æ¬ æå€¤æ•°'})
    markdown_report.append("## æ¬ æå€¤ã®æ•°")
    if not missing_df.empty:
        markdown_report.append(missing_df.to_markdown(index=False))
    else:
        markdown_report.append("æ¬ æå€¤ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    markdown_report.append("\n")

    # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆé‡
    numeric_desc = df.describe(include=['number'])
    markdown_report.append("## æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆé‡")
    if not numeric_desc.empty:
        markdown_report.append(numeric_desc.to_markdown())
    else:
        markdown_report.append("æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    markdown_report.append("\n")

    # ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆé‡
    markdown_report.append("## ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ï¼ˆæ–‡å­—åˆ—ãªã©ï¼‰ã®åŸºæœ¬çµ±è¨ˆé‡")
    categorical_cols = df.select_dtypes(include=['object', 'category'])
    if not categorical_cols.empty:
         cat_desc = df.describe(include=['object', 'category'])
         markdown_report.append(cat_desc.to_markdown())
    else:
         markdown_report.append("ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    markdown_report.append("\n")

    return "\n".join(markdown_report)

def display_exploration(df):
    """Streamlitä¸Šã§ãƒ‡ãƒ¼ã‚¿æ¢ç´¢çµæœã‚’è¡¨ç¤ºã™ã‚‹"""
    with st.expander("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è©³ç´°ã‚’è¡¨ç¤º"):
        st.subheader("åŸºæœ¬æƒ…å ±")
        st.write(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ (è¡Œæ•°, åˆ—æ•°): {df.shape}")

        st.subheader("ãƒ‡ãƒ¼ã‚¿å‹")
        dtypes_df = df.dtypes.reset_index().rename(columns={'index': 'åˆ—å', 0: 'ãƒ‡ãƒ¼ã‚¿å‹'})
        # ãƒ‡ãƒ¼ã‚¿å‹åˆ—ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ã‹ã‚‰è¡¨ç¤º
        dtypes_df['ãƒ‡ãƒ¼ã‚¿å‹'] = dtypes_df['ãƒ‡ãƒ¼ã‚¿å‹'].astype(str)
        st.dataframe(dtypes_df)

        st.subheader("æ¬ æå€¤ã®æ•°")
        missing_values = df.isnull().sum()
        missing_df = missing_values[missing_values > 0].reset_index().rename(columns={'index': 'åˆ—å', 0: 'æ¬ æå€¤æ•°'})
        if not missing_df.empty:
            # å¿µã®ãŸã‚å‹ã‚’ç¢ºèªã™ã‚‹å ´åˆãŒã‚ã‚‹ãŒã€é€šå¸¸ã“ã®DFã¯å•é¡Œãªã„ã¯ãš
            st.dataframe(missing_df)
        else:
            st.write("æ¬ æå€¤ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")


        st.subheader("æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆé‡")
        numeric_desc = df.describe(include=['number'])
        if not numeric_desc.empty:
             # describeã®çµæœã¯é€šå¸¸æ•°å€¤ãªã®ã§å•é¡Œãªã„ã“ã¨ãŒå¤šã„
             st.dataframe(numeric_desc)
        else:
             st.write("æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")


        st.subheader("ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ï¼ˆæ–‡å­—åˆ—ãªã©ï¼‰ã®åŸºæœ¬çµ±è¨ˆé‡")
        categorical_cols = df.select_dtypes(include=['object', 'category'])
        if not categorical_cols.empty:
             cat_desc = df.describe(include=['object', 'category'])
             # describe(include='object') ã®çµæœã¯å‹ãŒæ··åœ¨ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€å…¨ä½“ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
             st.dataframe(cat_desc.astype(str))
        else:
             st.write("ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

        # --- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ --- #
        st.markdown("---") # åŒºåˆ‡ã‚Šç·š
        report_md = generate_exploration_report(df)
        st.download_button(
            label="ğŸ“Š æ¢ç´¢çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.md)",
            data=report_md,
            file_name="data_exploration_report.md",
            mime="text/markdown",
        )


def filter_data_by_date(df, date_col, selected_date):
    """æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜åˆ—ã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹"""
    if not pd.api.types.is_datetime64_any_dtype(df[date_col]):
         st.error(f"ã‚¨ãƒ©ãƒ¼: åˆ— '{date_col}' ã¯æ—¥ä»˜å‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å‰å‡¦ç†ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
         return pd.DataFrame() # ç©ºã®DataFrameã‚’è¿”ã™
    try:
        # selected_dateã‚‚datetimeå‹ã«å¤‰æ›ã—ã¦æ¯”è¼ƒ
        selected_datetime = pd.to_datetime(selected_date).date() # æ—¥ä»˜éƒ¨åˆ†ã®ã¿ã§æ¯”è¼ƒ
        return df[df[date_col].dt.date == selected_datetime]
    except Exception as e:
        st.error(f"æ—¥ä»˜ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

def find_last_price_change_lead_time(df_filtered, price_cols, lead_time_col):
    """
    æŒ‡å®šã•ã‚ŒãŸä¾¡æ ¼åˆ—ã«ã¤ã„ã¦ã€ä¾¡æ ¼ãŒæœ€å¾Œã«å¤‰æ›´ã•ã‚ŒãŸãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚’è¿”ã™ã€‚
    å¤‰æ›´ãŒãªã„å ´åˆã¯Noneã‚’è¿”ã™ã€‚
    è¤‡æ•°ã®ä¾¡æ ¼åˆ—ãŒã‚ã‚‹å ´åˆã€æœ€ã‚‚å°ã•ã„ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼ˆåˆ©ç”¨æ—¥ã«è¿‘ã„ï¼‰ã‚’è¿”ã™ã€‚
    ä¾¡æ ¼å¤‰å‹•ãŒå…¨ããªã„ä¾¡æ ¼åˆ—ã¯ã€æœ€çµ‚å¤‰æ›´ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã®æ±ºå®šã«å½±éŸ¿ã—ãªã„ã€‚
    """
    last_change_lead_time = float('inf')
    # changed = False # changed_in_any_active_col ã«ç½®ãæ›ãˆ

    if df_filtered.empty or lead_time_col not in df_filtered.columns:
        st.warning("ä¾¡æ ¼å¤‰æ›´ç‚¹æ¤œå‡º: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒç©ºã€ã¾ãŸã¯ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None

    # ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã§ã‚½ãƒ¼ãƒˆ (é™é †: å¤§ãã„æ–¹ã‹ã‚‰å°ã•ã„æ–¹ã¸)
    df_sorted = df_filtered.sort_values(by=lead_time_col, ascending=False)

    active_price_cols = []
    for price_col in price_cols:
        if price_col not in df_sorted.columns:
            st.warning(f"ä¾¡æ ¼å¤‰æ›´ç‚¹æ¤œå‡º: ä¾¡æ ¼åˆ— '{price_col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue
        # dropna=True ã§ NaN ã‚’ç„¡è¦–ã—ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®æ•°ã‚’æ•°ãˆã‚‹
        if df_sorted[price_col].nunique(dropna=True) > 1:
            active_price_cols.append(price_col)
        else:
            st.info(f"ä¾¡æ ¼å¤‰æ›´ç‚¹æ¤œå‡º: ä¾¡æ ¼åˆ— '{price_col}' ã«ã¯ä¾¡æ ¼å¤‰å‹•ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã“ã®åˆ—ã¯åˆ†æã‹ã‚‰é™¤å¤–ã•ã‚Œã¾ã™ã€‚")

    if not active_price_cols:
        st.info("ä¾¡æ ¼æœ€çµ‚å¤‰æ›´ç‚¹æ¤œå‡º: åˆ†æå¯¾è±¡ã®ä¾¡æ ¼åˆ—ã®ä¸­ã«ã€ä¾¡æ ¼å¤‰å‹•ã®ã‚ã£ãŸåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None

    changed_in_any_active_col = False # åˆæœŸåŒ–

    for price_col in active_price_cols: # å¤‰å‹•ãŒã‚ã£ãŸåˆ—ã®ã¿ã‚’ãƒ«ãƒ¼ãƒ—
        if price_col not in df_sorted.columns:
            # active_price_colsç”Ÿæˆæ™‚ã«ãƒã‚§ãƒƒã‚¯æ¸ˆã¿ã ãŒå¿µã®ãŸã‚
            # st.warning(f"ä¾¡æ ¼å¤‰æ›´ç‚¹æ¤œå‡º: ä¾¡æ ¼åˆ— '{price_col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            continue

        price_values = df_sorted[price_col]
        # æœ‰åŠ¹ãªï¼ˆNaNã§ãªã„ï¼‰ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒ2ã¤æœªæº€ã®å ´åˆã€å¤‰å‹•ã‚’æ¤œå‡ºã—ã‚ˆã†ãŒãªã„
        if price_values.count() < 2:
            # st.info(f"ä¾¡æ ¼åˆ— '{price_col}' ã®æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒ2æœªæº€ã®ãŸã‚ã€å¤‰å‹•ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã€‚")
            continue

        # ç¾åœ¨ã®è¡Œã®ä¾¡æ ¼ã¨ã€å‰ã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼ˆdf_sortedã§ã¯1ã¤å‰ã®è¡Œï¼‰ã®ä¾¡æ ¼ã‚’æ¯”è¼ƒ
        # df_sortedã¯ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ é™é †ãªã®ã§ã€shift(1)ã¯æ™‚é–“çš„ã«ã€Œéå»ã€ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ å¤§ï¼‰
        shifted_prices = price_values.shift(1)
        price_changes = price_values.ne(shifted_prices)

        # æœ€åˆã®è¡Œ(æœ€å¤§ã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ )ã¯å¸¸ã«å¤‰åŒ–ãªã—ã¨ã™ã‚‹ (shift(1)ã®çµæœãŒNaNã«ãªã‚‹ãŸã‚æ¯”è¼ƒçµæœã«å½±éŸ¿)
        if not price_changes.empty:
            price_changes.iloc[0] = False

        change_indices = price_changes[price_changes].index

        if not change_indices.empty:
            # æœ€ã‚‚ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ãŒå°ã•ã„å¤‰åŒ–ç‚¹ã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚’å–å¾—
            current_col_last_change_lt = df_sorted.loc[change_indices, lead_time_col].min()
            last_change_lead_time = min(last_change_lead_time, current_col_last_change_lt)
            changed_in_any_active_col = True
        # else:
            # st.info(f"ä¾¡æ ¼åˆ— '{price_col}' ã§ã¯ä¾¡æ ¼å¤‰å‹•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚") # active_price_colsã§ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ãªã®ã§ä¸è¦


    if not changed_in_any_active_col:
        # active_price_cols ãŒç©ºã§ãªã‹ã£ãŸã®ã«ã“ã“ã«åˆ°é”ã™ã‚‹å ´åˆã€
        # ä¾‹ãˆã°ã€å¤‰å‹•ã¯ã‚ã‚‹ãŒå…¨ã¦NaNã«ãªã£ãŸãªã©ã®ç‰¹æ®Šã‚±ãƒ¼ã‚¹ã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒæ¥µç«¯ã«å°‘ãªã„å ´åˆã€‚
        st.info("ä¾¡æ ¼æœ€çµ‚å¤‰æ›´ç‚¹æ¤œå‡º: ä¾¡æ ¼å¤‰å‹•ã®ã‚ã‚‹åˆ—ã¯å­˜åœ¨ã—ã¾ã—ãŸãŒã€å…·ä½“çš„ãªå¤‰æ›´ç‚¹ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å¯èƒ½æ€§ãªã©ï¼‰ã€‚")
        return None
    elif last_change_lead_time == float('inf'):
         # changed_in_any_active_col ãŒ True ãªã®ã« inf ã®ã¾ã¾ -> ãƒ­ã‚¸ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§
         st.error("ä¾¡æ ¼æœ€çµ‚å¤‰æ›´ç‚¹æ¤œå‡º: äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã€‚å¤‰å‹•ã¯ã‚ã£ãŸãŒãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ãŒç„¡é™å¤§ã®ã¾ã¾ã§ã™ã€‚")
         return None
    else:
        # st.info(f"ä¾¡æ ¼æœ€çµ‚å¤‰æ›´ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ : {last_change_lead_time}")
        return int(last_change_lead_time) # æ•´æ•°ã§è¿”ã™


def create_scenario_data(df_filtered, price_cols, lead_time_col, scenario_type='mean', specific_prices=None, change_lead_time=None):
    """ä¾¡æ ¼å¤‰å‹•ã‚·ãƒŠãƒªã‚ªã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹"""
    df_scenario = df_filtered.copy()

    # --- ã‚·ãƒŠãƒªã‚ªåˆ¥ã®ä¾¡æ ¼è¨­å®š ---
    if scenario_type == 'mean':
        # --- å¹³å‡ä¾¡æ ¼ã‚·ãƒŠãƒªã‚ª ---
        mean_prices = {}
        all_cols_found = True
        for col in price_cols:
            if col in df_scenario.columns and pd.api.types.is_numeric_dtype(df_scenario[col]):
                # NaNã‚’é™¤å¤–ã—ã¦å¹³å‡ã‚’è¨ˆç®—
                mean_prices[col] = df_scenario[col].mean(skipna=True)
                if pd.isna(mean_prices[col]):
                    st.warning(f"è­¦å‘Š: å¹³å‡ä¾¡æ ¼è¨ˆç®—ã§åˆ— '{col}' ãŒå…¨ã¦NaNã§ã—ãŸã€‚")
                    # ã“ã®å ´åˆã€ä¾¡æ ¼ã¯å¤‰æ›´ã•ã‚Œãªã„
            else:
                 st.warning(f"è­¦å‘Š: ã‚·ãƒŠãƒªã‚ªä½œæˆã®ãŸã‚ã€åˆ— '{col}' ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹æ•°å€¤å‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                 all_cols_found = False
                 # return pd.DataFrame() # ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦ç©ºã‚’è¿”ã™ã‹ã€å‡¦ç†ã‚’ç¶šã‘ã‚‹ã‹

        if all_cols_found and mean_prices:
            st.info(f"ã‚·ãƒŠãƒªã‚ªä½œæˆ (å¹³å‡ä¾¡æ ¼): æœŸé–“ä¸­ã®å¹³å‡ä¾¡æ ¼ { {k: round(v, 2) for k, v in mean_prices.items()} } ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            for col, mean_val in mean_prices.items():
                if not pd.isna(mean_val): # è¨ˆç®—ã§ããŸå¹³å‡å€¤ã®ã¿é©ç”¨
                    df_scenario[col] = mean_val
        else:
            st.error("å¹³å‡ä¾¡æ ¼ã‚·ãƒŠãƒªã‚ªãƒ‡ãƒ¼ã‚¿ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return pd.DataFrame()


    elif scenario_type == 'last_change_fixed' and change_lead_time is not None:
        # --- ä¾¡æ ¼æœ€çµ‚å¤‰æ›´ç‚¹ä»¥é™å›ºå®šã‚·ãƒŠãƒªã‚ª ---
        st.info(f"ã‚·ãƒŠãƒªã‚ªä½œæˆ (æœ€çµ‚å¤‰æ›´ç‚¹å›ºå®š): ä¾¡æ ¼æœ€çµ‚å¤‰æ›´ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  ({change_lead_time}) ä»¥é™ã®ä¾¡æ ¼ã‚’å›ºå®šã—ã¾ã™ã€‚")

        # åŸºæº–ã¨ãªã‚‹ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ æ™‚ç‚¹ã§ã®ä¾¡æ ¼ã‚’å–å¾—
        prices_at_change_time = {}
        base_data_rows = df_scenario[df_scenario[lead_time_col] == change_lead_time]

        if base_data_rows.empty:
             # å®Œå…¨ä¸€è‡´ã™ã‚‹è¡ŒãŒãªã„å ´åˆã€ãã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  *ä»¥å‰* ã§æœ€ã‚‚è¿‘ã„è¡Œã‚’æ¢ã™
             available_lead_times_before = df_scenario[df_scenario[lead_time_col] <= change_lead_time][lead_time_col]
             if not available_lead_times_before.empty:
                 closest_lead_time = available_lead_times_before.max() # change_lead_time ã«æœ€ã‚‚è¿‘ã„ï¼ˆåŒã˜ã‹å°ã•ã„ï¼‰LT
                 st.info(f"ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  {change_lead_time} ã®æ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿ç‚¹ãŒãªã„ãŸã‚ã€æœ€ã‚‚è¿‘ã„éå»ã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  {closest_lead_time} ã®ä¾¡æ ¼ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                 base_data_rows = df_scenario[df_scenario[lead_time_col] == closest_lead_time]
             else:
                 st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  {change_lead_time} ã¾ãŸã¯ãã‚Œä»¥å‰ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                 return pd.DataFrame()

        if base_data_rows.empty:
             st.error(f"ã‚¨ãƒ©ãƒ¼: åŸºæº–ã¨ãªã‚‹ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  {change_lead_time} (ã¾ãŸã¯ãã‚Œä»¥å‰)ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
             return pd.DataFrame()

        # è¤‡æ•°è¡Œã‚ã‚‹å ´åˆã‚‚æœ€åˆã®è¡Œã®ä¾¡æ ¼ã‚’ä½¿ã†ï¼ˆã‚½ãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹å‰æãªã‚‰å•é¡Œãªã„ã¯ãšï¼‰
        base_row = base_data_rows.iloc[0]
        all_prices_found = True
        for col in price_cols:
            if col in base_row.index and not pd.isna(base_row[col]):
                prices_at_change_time[col] = base_row[col]
            else:
                 st.warning(f"è­¦å‘Š: å›ºå®šä¾¡æ ¼å–å¾—ã®ãŸã‚ã€åˆ— '{col}' ãŒãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  {base_row[lead_time_col]} ã§è¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€å€¤ãŒNaNã§ã™ã€‚")
                 prices_at_change_time[col] = None # Noneã‚’è¨­å®š
                 all_prices_found = False # ä¸€ã¤ã§ã‚‚ä¾¡æ ¼ãŒå–ã‚Œãªã„å ´åˆã¯ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹

        # ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ãŒ change_lead_time ä»¥ä¸‹ã®è¡Œã®ä¾¡æ ¼ã‚’å›ºå®šä¾¡æ ¼ã§ä¸Šæ›¸ã
        target_period_mask = df_scenario[lead_time_col] <= change_lead_time
        st.write(f"ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  {change_lead_time} ä»¥ä¸‹ã®æœŸé–“ã®ä¾¡æ ¼ã‚’ {prices_at_change_time} ã§å›ºå®šã—ã¾ã™ã€‚")

        for col, fixed_price in prices_at_change_time.items():
            if fixed_price is not None and col in df_scenario.columns:
                df_scenario.loc[target_period_mask, col] = fixed_price
            elif col in df_scenario.columns:
                 # fixed_priceãŒNoneã®å ´åˆ (ä¸Šã§è­¦å‘Šæ¸ˆã¿)
                 # st.warning(f"è­¦å‘Š: åˆ— '{col}' ã®å›ºå®šä¾¡æ ¼ãŒå–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€æ›´æ–°ã—ã¾ã›ã‚“ã€‚")
                 pass


    elif scenario_type == 'specific' and specific_prices:
        # --- ç‰¹å®šä¾¡æ ¼æŒ‡å®šã‚·ãƒŠãƒªã‚ª ---
        st.info(f"ã‚·ãƒŠãƒªã‚ªä½œæˆ (æŒ‡å®šä¾¡æ ¼): æŒ‡å®šã•ã‚ŒãŸä¾¡æ ¼ {specific_prices} ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        if len(price_cols) != len(specific_prices):
             st.error("ã‚¨ãƒ©ãƒ¼: ã‚·ãƒŠãƒªã‚ªä¾¡æ ¼ã®ãƒªã‚¹ãƒˆé•·ãŒprice_colsã¨ä¸€è‡´ã—ã¾ã›ã‚“ã€‚")
             return pd.DataFrame()
        prices_to_set = dict(zip(price_cols, specific_prices))
        for col, price_val in prices_to_set.items():
            if col in df_scenario.columns:
                df_scenario[col] = price_val
            else:
                 st.warning(f"è­¦å‘Š: ã‚·ãƒŠãƒªã‚ªä¾¡æ ¼ã‚’è¨­å®šã™ã‚‹åˆ— '{col}' ãŒãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")


    else:
        # 'mean' ä»¥å¤–ã§ã€é©åˆ‡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãªã„å ´åˆ
        if scenario_type != 'mean':
             st.error(f"ã‚¨ãƒ©ãƒ¼: ç„¡åŠ¹ãªã‚·ãƒŠãƒªã‚ªã‚¿ã‚¤ãƒ—({scenario_type})ã¾ãŸã¯å¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
             return pd.DataFrame() # ç©ºã®DFã‚’è¿”ã™
        # 'mean' ã‚·ãƒŠãƒªã‚ªã®å ´åˆã¯ä¸Šã§å‡¦ç†ã•ã‚Œã¦ã„ã‚‹


    # --- ä¾¡æ ¼å·®ç‰¹å¾´é‡ã®å†è¨ˆç®— (å…±é€šå‡¦ç†) ---
    if all(col in df_scenario.columns for col in price_cols):
        # å†è¨ˆç®—å‰ã«æ•°å€¤å‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        all_numeric = True
        for col in price_cols:
            try:
                df_scenario[col] = pd.to_numeric(df_scenario[col], errors='raise') # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ã“ã“ã§åœæ­¢
            except Exception as e:
                st.error(f"ä¾¡æ ¼å·®å†è¨ˆç®—ã‚¨ãƒ©ãƒ¼: åˆ— '{col}' ã‚’æ•°å€¤ã«å¤‰æ›ã§ãã¾ã›ã‚“: {e}")
                all_numeric = False
                break # ãƒ«ãƒ¼ãƒ—ä¸­æ–­

        if all_numeric:
            # NaNãƒã‚§ãƒƒã‚¯ (æ•°å€¤å¤‰æ›å¾Œãªã®ã§ isna() ã§OK)
            if df_scenario[price_cols].isna().any().any():
                 st.warning(f"è­¦å‘Š: ã‚·ãƒŠãƒªã‚ªãƒ‡ãƒ¼ã‚¿ã®ä¾¡æ ¼åˆ— '{', '.join(price_cols)}' ã«NaNãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ä¾¡æ ¼å·®/æ¯”ã®è¨ˆç®—çµæœã‚‚NaNã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            try:
                df_scenario['ä¾¡æ ¼å·®'] = df_scenario[price_cols[0]].sub(df_scenario[price_cols[1]], fill_value=np.nan) # fill_value=np.nanæ¨å¥¨
                # ä¾¡æ ¼æ¯” (ã‚¼ãƒ­é™¤ç®—ã¨NaNã‚’è€ƒæ…®)
                denominator = df_scenario[price_cols[1]].replace(0, np.nan) # 0ã‚’NaNã«ç½®æ›
                df_scenario['ä¾¡æ ¼æ¯”'] = df_scenario[price_cols[0]].div(denominator) # ã“ã‚Œã§NaNä¼æ’­ã¨ã‚¼ãƒ­é™¤ç®—å›é¿
            except Exception as e:
                st.error(f"ä¾¡æ ¼å·®/æ¯”ã®å†è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                # å¿…è¦ã«å¿œã˜ã¦ 'ä¾¡æ ¼å·®', 'ä¾¡æ ¼æ¯”' åˆ—ã‚’å‰Šé™¤ã¾ãŸã¯NaNã§åŸ‹ã‚ã‚‹
                if 'ä¾¡æ ¼å·®' in df_scenario.columns: df_scenario['ä¾¡æ ¼å·®'] = np.nan
                if 'ä¾¡æ ¼æ¯”' in df_scenario.columns: df_scenario['ä¾¡æ ¼æ¯”'] = np.nan

    # else:
        # ä¾¡æ ¼åˆ—ãŒæƒã£ã¦ã„ãªã„å ´åˆã¯è­¦å‘Šæ¸ˆã¿ã®ã¯ãš

    st.success(f"ã‚·ãƒŠãƒªã‚ªãƒ‡ãƒ¼ã‚¿ ({scenario_type}) ä½œæˆå®Œäº†ã€‚")
    return df_scenario 