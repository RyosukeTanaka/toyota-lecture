# utils/page_batch_analysis.py

import streamlit as st
import pandas as pd
import datetime
import os
from typing import Dict, Any, List, Optional, Tuple
import concurrent.futures
import plotly.io as pio

from .constants import (
    TARGET_VARIABLE, DATE_COLUMN, PRICE_COLUMNS, LEAD_TIME_COLUMN,
    CAR_CLASS_COLUMN, BOOKING_DATE_COLUMN, USAGE_COUNT_COLUMN
)
from .ui_components import render_prediction_sidebar_widgets
from .model_storage import load_model, get_model_metadata, list_saved_models
from .batch_analysis import run_batch_prediction
from .visualization import plot_batch_revenue_comparison

# ---- ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (ä¸€æ™‚çš„ã«å‡¦ç†ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ) ----
def _save_image_task(fig: Any, filepath: str):
    """Plotlyã®å›³ã‚’ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ç”¨ï¼‰"""
    # try:
    #     pio.write_image(fig, filepath)
    #     # print(f"ç”»åƒä¿å­˜å®Œäº†: {filepath}") # ãƒ‡ãƒãƒƒã‚°ç”¨ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
    #     return f"Successfully saved {filepath}"
    # except Exception as e:
    #     # print(f"ç”»åƒä¿å­˜ã‚¨ãƒ©ãƒ¼ {filepath}: {e}") # ãƒ‡ãƒãƒƒã‚°ç”¨ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
    #     return f"Error saving {filepath}: {e}"
    st.warning(f"ç”»åƒä¿å­˜å‡¦ç†ã¯ä¸€æ™‚çš„ã«ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ: {filepath}")
    return f"Image saving skipped for {filepath}" # ã‚¹ã‚­ãƒƒãƒ—ã—ãŸã“ã¨ã‚’ç¤ºã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

def save_batch_results_to_folder(
    metadata_list: Optional[List[Dict[str, Any]]], 
    date_revenue_df: Optional[pd.DataFrame], 
    class_revenue_df: Optional[pd.DataFrame],
    result_df: Optional[pd.DataFrame],
    fig_date: Optional[Any], 
    fig_class: Optional[Any] 
) -> Optional[str]:
    """ãƒãƒƒãƒåˆ†æçµæœã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã™ã‚‹"""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = f"batch_results_{timestamp}"
    try:
        if not os.path.exists(results_dir):
            os.makedirs(results_dir)
    except OSError as e:
        st.error(f"çµæœä¿å­˜ç”¨ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {results_dir} ({e})")
        return None
    
    try:
        if result_df is not None and not result_df.empty:
            result_df.to_csv(os.path.join(results_dir, "batch_analysis_results.csv"), index=False, encoding='utf-8-sig')
        if date_revenue_df is not None and not date_revenue_df.empty:
            date_revenue_df.to_csv(os.path.join(results_dir, "date_revenue_summary.csv"), index=False, encoding='utf-8-sig')
        if class_revenue_df is not None and not class_revenue_df.empty:
            class_revenue_df.to_csv(os.path.join(results_dir, "class_revenue_summary.csv"), index=False, encoding='utf-8-sig')
    except Exception as e:
        st.warning(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    try:
        if fig_date:
            fig_date.write_html(os.path.join(results_dir, "date_revenue_chart.html"))
        if fig_class:
            fig_class.write_html(os.path.join(results_dir, "class_revenue_chart.html"))
    except Exception as e:
        st.warning(f"HTMLã‚°ãƒ©ãƒ•ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # ç”»åƒä¿å­˜ã‚¿ã‚¹ã‚¯ã®å‘¼ã³å‡ºã—ã‚’ä¸€æ™‚çš„ã«å¤‰æ›´ (ã‚‚ã—ãã¯å®Œå…¨ã«ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ)
    image_tasks = []
    if fig_date:
        image_tasks.append((fig_date, os.path.join(results_dir, "date_revenue_chart.png")))
    if fig_class:
        image_tasks.append((fig_class, os.path.join(results_dir, "class_revenue_chart.png")))

    if image_tasks:
        # st.info(f"ã‚°ãƒ©ãƒ•ç”»åƒã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã—ãŸ ({len(image_tasks)}ä»¶)ã€‚å®Œäº†ã¾ã§æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ä¿å­˜å…ˆ: {os.path.abspath(results_dir)}")
        # try:
        #     with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor: 
        #         futures = [executor.submit(_save_image_task, fig, fp) for fig, fp in image_tasks]
        # except Exception as e:
        #     st.error(f"ç”»åƒä¿å­˜ã‚¿ã‚¹ã‚¯ã®èµ·å‹•ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.warning("PNGç”»åƒã®ä¿å­˜å‡¦ç†ã¯ã€å•é¡Œèª¿æŸ»ã®ãŸã‚ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚")
        # å„ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦åŒæœŸçš„ã«ï¼ˆãŸã ã—ä¸­èº«ã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ï¼‰å‘¼ã³å‡ºã—ã‚’è¡Œã†
        for fig, fp in image_tasks:
            _save_image_task(fig, fp) # ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã¯å‘¼ã³å‡ºã™ãŒã€ä¸­èº«ã¯ã‚¹ã‚­ãƒƒãƒ—

    try:
        if metadata_list: 
            success_count = sum(1 for meta in metadata_list if meta.get("success", False))
            fail_count = len(metadata_list) - success_count
            success_data = [meta for meta in metadata_list if meta.get("success", False)]
            total_actual = sum(meta.get("revenue_actual", 0) for meta in success_data)
            total_predicted = sum(meta.get("revenue_predicted", 0) for meta in success_data)
            total_difference = sum(meta.get("revenue_difference", 0) for meta in success_data)
            
            with open(os.path.join(results_dir, "summary.txt"), "w", encoding='utf-8') as f:
                f.write(f"ãƒãƒƒãƒåˆ†æã‚µãƒãƒªãƒ¼\n")
                f.write(f"å®Ÿè¡Œæ—¥æ™‚: {timestamp}\n")
                f.write(f"=================================\n")
                f.write(f"å‡¦ç†ç·æ•°: {len(metadata_list)}ä»¶\n")
                f.write(f"æˆåŠŸ: {success_count}ä»¶, å¤±æ•—: {fail_count}ä»¶\n\n")
                f.write(f"å£²ä¸Šé›†è¨ˆçµæœ:\n")
                f.write(f"å®Ÿç¸¾ç·å£²ä¸Š: {int(total_actual):,}å††\n")
                f.write(f"äºˆæ¸¬ç·å£²ä¸Šï¼ˆä¾¡æ ¼å›ºå®šï¼‰: {int(total_predicted):,}å††\n")
                f.write(f"å£²ä¸Šå·®é¡ï¼ˆå®Ÿç¸¾-äºˆæ¸¬ï¼‰: {int(total_difference):,}å††\n\n")
                if total_difference > 0:
                    f.write(f"å…¨ä½“åˆ†æ: æœŸé–“å…¨ä½“ã§ä¾¡æ ¼å¤‰æ›´ã«ã‚ˆã‚Š {int(total_difference):,}å†† ã®è¿½åŠ å£²ä¸ŠãŒç™ºç”Ÿã—ãŸã¨æ¨å®šã•ã‚Œã¾ã™ã€‚ä¾¡æ ¼æˆ¦ç•¥ã¯æœ‰åŠ¹ã«æ©Ÿèƒ½ã—ã¦ã„ã¾ã™ã€‚\n")
                elif total_difference < 0:
                    f.write(f"å…¨ä½“åˆ†æ: æœŸé–“å…¨ä½“ã§ä¾¡æ ¼å¤‰æ›´ã«ã‚ˆã‚Š {abs(int(total_difference)):,}å†† ã®å£²ä¸Šæ¸›å°‘ãŒã‚ã£ãŸã¨æ¨å®šã•ã‚Œã¾ã™ã€‚ä¾¡æ ¼æˆ¦ç•¥ã®è¦‹ç›´ã—ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\n")
                else:
                    f.write(f"å…¨ä½“åˆ†æ: æœŸé–“å…¨ä½“ã§ä¾¡æ ¼å¤‰æ›´ã«ã‚ˆã‚‹å£²ä¸Šã¸ã®é¡•è‘—ãªå½±éŸ¿ã¯è¦‹ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n")
    except Exception as e:
        st.warning(f"ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    try:
        error_data = [meta for meta in metadata_list if not meta.get("success", False)] if metadata_list else []
        if error_data:
            error_df = pd.DataFrame([
                {"æ—¥ä»˜": meta.get("date"), "è»Šä¸¡ã‚¯ãƒ©ã‚¹": meta.get("car_class"), "ãƒ¢ãƒ‡ãƒ«": meta.get("model_name", "ä¸æ˜"), "ã‚¨ãƒ©ãƒ¼å†…å®¹": meta.get("error", "ä¸æ˜")}
                for meta in error_data
            ])
            error_df.to_csv(os.path.join(results_dir, "error_details.csv"), index=False, encoding='utf-8-sig')
    except Exception as e:
        st.warning(f"ã‚¨ãƒ©ãƒ¼è©³ç´°CSVã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    st.success(f"ğŸ—‚ï¸ CSVã€HTMLã€ãŠã‚ˆã³ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®ä¿å­˜å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ç”»åƒä¿å­˜ã¯ä¸€æ™‚çš„ã«ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¿å­˜å…ˆ: {os.path.abspath(results_dir)}")
    return os.path.abspath(results_dir)

# ã“ã®é–¢æ•°ã‚’ãƒšãƒ¼ã‚¸å†…ã§çµæœè¡¨ç¤ºç”¨ã«ä½¿ç”¨ã™ã‚‹
def display_batch_results_in_page(metadata_list: Optional[List[Dict[str, Any]]], return_figures: bool = False) -> Optional[Tuple[Optional[pd.DataFrame], Optional[Any], Optional[Any], Optional[pd.DataFrame], Optional[pd.DataFrame]]]:
    """ãƒãƒƒãƒå‡¦ç†çµæœã®é›†è¨ˆè¡¨ç¤ºï¼ˆãƒšãƒ¼ã‚¸å†…ã§ã®è¡¨ç¤ºç”¨ï¼‰"""
    if not metadata_list:
        st.warning("ãƒãƒƒãƒå‡¦ç†çµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return (None, None, None, None, None) if return_figures else None
        
    success_count = sum(1 for meta in metadata_list if meta.get("success", False))
    fail_count = len(metadata_list) - success_count
    
    st.metric("å‡¦ç†ç·æ•°", f"{len(metadata_list)}ä»¶", f"æˆåŠŸ: {success_count}ä»¶, å¤±æ•—: {fail_count}ä»¶")
    
    result_df_display: Optional[pd.DataFrame] = None
    fig_date_display: Optional[Any] = None
    fig_class_display: Optional[Any] = None
    date_revenue_df_display: Optional[pd.DataFrame] = None
    class_revenue_df_display: Optional[pd.DataFrame] = None

    if success_count == 0:
        st.error("ã™ã¹ã¦ã®å‡¦ç†ãŒå¤±æ•—ã—ã¾ã—ãŸ")
        error_df_display = pd.DataFrame([
            {"æ—¥ä»˜": meta.get("date"), "è»Šä¸¡ã‚¯ãƒ©ã‚¹": meta.get("car_class"), "ãƒ¢ãƒ‡ãƒ«": meta.get("model_name", "ä¸æ˜"), "ã‚¨ãƒ©ãƒ¼å†…å®¹": meta.get("error", "ä¸æ˜")}
            for meta in metadata_list if not meta.get("success", False)
        ])
        st.dataframe(error_df_display)
        if return_figures:
            return error_df_display, None, None, None, None
        return None
    
    success_data = [meta for meta in metadata_list if meta.get("success", False)]
    total_actual = sum(meta.get("revenue_actual", 0) for meta in success_data)
    total_predicted = sum(meta.get("revenue_predicted", 0) for meta in success_data)
    total_difference = sum(meta.get("revenue_difference", 0) for meta in success_data)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å®Ÿç¸¾ç·å£²ä¸Š", f"{int(total_actual):,}å††")
    with col2:
        st.metric("äºˆæ¸¬ç·å£²ä¸Šï¼ˆä¾¡æ ¼å›ºå®šï¼‰", f"{int(total_predicted):,}å††")
    with col3:
        delta_color = "normal" if total_difference >= 0 else "inverse"
        st.metric("å£²ä¸Šå·®é¡ï¼ˆå®Ÿç¸¾-äºˆæ¸¬ï¼‰", f"{int(total_difference):,}å††", 
                delta=f"{int(total_difference):,}å††", delta_color=delta_color)
    
    result_df_display = pd.DataFrame([
        {
            "åˆ©ç”¨æ—¥": meta.get("date"),
            "è»Šä¸¡ã‚¯ãƒ©ã‚¹": meta.get("car_class"),
            "ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«": meta.get("model_name", "ä¸æ˜"),
            "ä¾¡æ ¼å¤‰æ›´ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ": meta.get("last_change_lt"),
            "å®Ÿç¸¾å£²ä¸Š": int(meta.get("revenue_actual", 0)),
            "äºˆæ¸¬å£²ä¸Š": int(meta.get("revenue_predicted", 0)),
            "å£²ä¸Šå·®é¡": int(meta.get("revenue_difference", 0))
        }
        for meta in success_data
    ])
    
    st.subheader("è©³ç´°çµæœ")
    st.dataframe(result_df_display.sort_values(by=["åˆ©ç”¨æ—¥", "è»Šä¸¡ã‚¯ãƒ©ã‚¹"]))
    
    st.subheader("æ—¥ä»˜åˆ¥å£²ä¸Šå·®é¡")
    date_revenue_df_display = result_df_display.groupby("åˆ©ç”¨æ—¥").agg({
        "å®Ÿç¸¾å£²ä¸Š": "sum", "äºˆæ¸¬å£²ä¸Š": "sum", "å£²ä¸Šå·®é¡": "sum"
    }).reset_index()
    if not date_revenue_df_display.empty:
        fig_date_display = plot_batch_revenue_comparison(date_revenue_df_display, "åˆ©ç”¨æ—¥")
        st.plotly_chart(fig_date_display, use_container_width=True)
    else:
        st.info("æ—¥ä»˜åˆ¥å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    st.subheader("è»Šä¸¡ã‚¯ãƒ©ã‚¹åˆ¥å£²ä¸Šå·®é¡")
    class_revenue_df_display = result_df_display.groupby("è»Šä¸¡ã‚¯ãƒ©ã‚¹").agg({
        "å®Ÿç¸¾å£²ä¸Š": "sum", "äºˆæ¸¬å£²ä¸Š": "sum", "å£²ä¸Šå·®é¡": "sum"
    }).reset_index()
    if not class_revenue_df_display.empty:
        fig_class_display = plot_batch_revenue_comparison(class_revenue_df_display, "è»Šä¸¡ã‚¯ãƒ©ã‚¹", horizontal=True)
        st.plotly_chart(fig_class_display, use_container_width=True)
    else:
        st.info("è»Šä¸¡ã‚¯ãƒ©ã‚¹åˆ¥å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        
    csv_download = result_df_display.to_csv(index=False).encode('utf-8')
    download_filename = f"batch_analysis_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    st.download_button("ğŸ’¾ é›†è¨ˆçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv_download, download_filename, "text/csv", key="download_batch_csv_page")
    
    if total_difference > 0:
        st.success(f"**å…¨ä½“åˆ†æ**: æœŸé–“å…¨ä½“ã§ä¾¡æ ¼å¤‰æ›´ã«ã‚ˆã‚Š **{int(total_difference):,}å††** ã®è¿½åŠ å£²ä¸ŠãŒç™ºç”Ÿã—ãŸã¨æ¨å®šã•ã‚Œã¾ã™ã€‚ä¾¡æ ¼æˆ¦ç•¥ã¯æœ‰åŠ¹ã«æ©Ÿèƒ½ã—ã¦ã„ã¾ã™ã€‚")
    elif total_difference < 0:
        st.warning(f"**å…¨ä½“åˆ†æ**: æœŸé–“å…¨ä½“ã§ä¾¡æ ¼å¤‰æ›´ã«ã‚ˆã‚Š **{abs(int(total_difference)):,}å††** ã®å£²ä¸Šæ¸›å°‘ãŒã‚ã£ãŸã¨æ¨å®šã•ã‚Œã¾ã™ã€‚ä¾¡æ ¼æˆ¦ç•¥ã®è¦‹ç›´ã—ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")
    else:
        st.info("**å…¨ä½“åˆ†æ**: æœŸé–“å…¨ä½“ã§ä¾¡æ ¼å¤‰æ›´ã«ã‚ˆã‚‹å£²ä¸Šã¸ã®é¡•è‘—ãªå½±éŸ¿ã¯è¦‹ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        
    if fail_count > 0:
        st.markdown("---")
        st.subheader("å¤±æ•—è©³ç´°")
        error_df_page = pd.DataFrame([
            {"æ—¥ä»˜": meta.get("date"), "è»Šä¸¡ã‚¯ãƒ©ã‚¹": meta.get("car_class"), "ãƒ¢ãƒ‡ãƒ«": meta.get("model_name", "ä¸æ˜"), "ã‚¨ãƒ©ãƒ¼å†…å®¹": meta.get("error", "ä¸æ˜")}
            for meta in metadata_list if not meta.get("success", False)
        ])
        st.dataframe(error_df_page)
    
    if return_figures:
        return result_df_display, fig_date_display, fig_class_display, date_revenue_df_display, class_revenue_df_display
    return None

def render_batch_analysis_page(data: pd.DataFrame, config: Dict[str, Any]):
    """è¤‡æ•°æ—¥ä»˜ãƒ»è»Šä¸¡ã‚¯ãƒ©ã‚¹ã®ãƒãƒƒãƒåˆ†æãƒšãƒ¼ã‚¸ã‚’æç”»"""
    st.title("è¤‡æ•°æ—¥ä»˜ç¯„å›²ã§ã®é›†è¨ˆåˆ†æ")
    
    _, _, _ = render_prediction_sidebar_widgets(data)
    saved_models = list_saved_models()
    if not saved_models:
        st.warning("äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ã¾ãšã€Œãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãƒšãƒ¼ã‚¸ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        return
    
    st.header("åˆ†æå¯¾è±¡è¨­å®š")
    st.markdown("è¤‡æ•°ã®æ—¥ä»˜ã¨è»Šä¸¡ã‚¯ãƒ©ã‚¹ã®çµ„ã¿åˆã‚ã›ã«å¯¾ã—ã¦ä¸€æ‹¬ã§äºˆæ¸¬åˆ†æã‚’è¡Œã„ã¾ã™ã€‚")
    with st.expander("åˆ†ææ‰‹æ³•ã®èª¬æ˜", expanded=True):
        st.markdown("""
        ### å£²ä¸Šé‡‘é¡å½±éŸ¿åˆ†æã®ä»•çµ„ã¿
        ã“ã®åˆ†æãƒ„ãƒ¼ãƒ«ã¯ã€**ä¾¡æ ¼å¤‰æ›´ãŒå£²ä¸Šã«ä¸ãˆãŸå½±éŸ¿**ã‚’å®šé‡çš„ã«è©•ä¾¡ã—ã¾ã™ã€‚
        1. **ä¾¡æ ¼å¤‰æ›´ç‚¹ã®ç‰¹å®š**: å„æ—¥ä»˜ãƒ»è»Šä¸¡ã‚¯ãƒ©ã‚¹ã”ã¨ã«ä¾¡æ ¼å¤‰æ›´ãŒã‚ã£ãŸæœ€å¾Œã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼ˆLTï¼‰ã‚’ç‰¹å®šã€‚
        2. **å®Ÿç¸¾å£²ä¸Šã®è¨ˆç®—**: å®Ÿéš›ã®äºˆç´„ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå£²ä¸Šã€‚
        3. **äºˆæ¸¬å£²ä¸Šã®è¨ˆç®—**: ã€Œä¾¡æ ¼ãŒå¤‰æ›´ã•ã‚Œãªã‹ã£ãŸå ´åˆã€ã®ã‚·ãƒŠãƒªã‚ªã«åŸºã¥ãäºˆæ¸¬å£²ä¸Šã€‚
        4. **å£²ä¸Šå·®é¡ã®ç®—å‡º**: å®Ÿç¸¾å£²ä¸Š - äºˆæ¸¬å£²ä¸Š = ä¾¡æ ¼å¤‰æ›´ã«ã‚ˆã‚‹å½±éŸ¿é¡ã€‚
        """)
    
    date_range = []
    with st.expander("æ—¥ä»˜ç¯„å›²ã®é¸æŠ", expanded=True):
        if DATE_COLUMN in data.columns and pd.api.types.is_datetime64_any_dtype(data[DATE_COLUMN]):
            available_dates = sorted(data[DATE_COLUMN].dt.date.unique())
            if available_dates:
                date_selection_method = st.radio("æ—¥ä»˜é¸æŠæ–¹æ³•", ["æ—¥ä»˜ç¯„å›²ã‚’æŒ‡å®š", "å€‹åˆ¥ã®æ—¥ä»˜ã‚’é¸æŠ"], horizontal=True, key="batch_date_select_method")
                if date_selection_method == "æ—¥ä»˜ç¯„å›²ã‚’æŒ‡å®š":
                    col1, col2 = st.columns(2)
                    min_date_val, max_date_val = available_dates[0], available_dates[-1]
                    default_start = datetime.date(2025, 4, 1)
                    default_start = default_start if min_date_val <= default_start <= max_date_val else min_date_val
                    start_date = st.date_input("é–‹å§‹æ—¥", default_start, min_value=min_date_val, max_value=max_date_val, key="batch_start_date")
                    default_end = datetime.date(2025, 4, 14)
                    default_end = default_end if start_date <= default_end <= max_date_val else max_date_val
                    end_date = st.date_input("çµ‚äº†æ—¥", default_end, min_value=start_date, max_value=max_date_val, key="batch_end_date")
                    date_range = [d for d in available_dates if start_date <= d <= end_date]
                else:
                    date_options = [d.strftime('%Y-%m-%d') for d in available_dates]
                    default_selection = [d.strftime('%Y-%m-%d') for d in available_dates if datetime.date(2025, 4, 1) <= d <= datetime.date(2025, 4, 14)]
                    if not default_selection: default_selection = date_options[:min(5, len(date_options))]
                    selected_dates_str = st.multiselect("åˆ†æã™ã‚‹æ—¥ä»˜ã‚’é¸æŠ", date_options, default=default_selection, key="batch_multi_date")
                    date_range = [datetime.datetime.strptime(d, '%Y-%m-%d').date() for d in selected_dates_str]
                st.info(f"é¸æŠã•ã‚ŒãŸæ—¥ä»˜: {len(date_range)}æ—¥")
                if date_range: st.dataframe(pd.DataFrame([{'åˆ©ç”¨æ—¥': d} for d in date_range]))
                else: st.warning("æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„")
            else: st.warning("åˆ©ç”¨å¯èƒ½ãªæ—¥ä»˜ãŒã‚ã‚Šã¾ã›ã‚“")
        else: st.error(f"'{DATE_COLUMN}'åˆ—ãŒãªã„ã‹æ—¥ä»˜å‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
    
    car_classes_selected_ui = []
    models_for_run = {}
    with st.expander("è»Šä¸¡ã‚¯ãƒ©ã‚¹ã¨ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ", expanded=True):
        if CAR_CLASS_COLUMN in data.columns:
            all_car_classes = sorted(data[CAR_CLASS_COLUMN].unique())
            models_by_class = {cls: [m for m in saved_models if m.get("car_class") == cls or m.get("car_class") == "å…¨ã‚¯ãƒ©ã‚¹"] for cls in all_car_classes}
            class_sel_method = st.radio("è»Šä¸¡ã‚¯ãƒ©ã‚¹é¸æŠæ–¹æ³•", ["ã™ã¹ã¦ã®è»Šä¸¡ã‚¯ãƒ©ã‚¹", "å€‹åˆ¥ã®è»Šä¸¡ã‚¯ãƒ©ã‚¹ã‚’é¸æŠ"], horizontal=True, key="batch_class_select_method")
            if class_sel_method == "ã™ã¹ã¦ã®è»Šä¸¡ã‚¯ãƒ©ã‚¹": car_classes_selected_ui = all_car_classes
            else: car_classes_selected_ui = st.multiselect("åˆ†æã™ã‚‹è»Šä¸¡ã‚¯ãƒ©ã‚¹ã‚’é¸æŠ", all_car_classes, default=[all_car_classes[0]] if all_car_classes else [], key="batch_multi_class")
            
            if car_classes_selected_ui:
                st.info(f"é¸æŠã•ã‚ŒãŸè»Šä¸¡ã‚¯ãƒ©ã‚¹: {len(car_classes_selected_ui)}ã‚¯ãƒ©ã‚¹")
                st.subheader("è»Šä¸¡ã‚¯ãƒ©ã‚¹ã”ã¨ã®ãƒ¢ãƒ‡ãƒ«é¸æŠ")
                for cls_item in car_classes_selected_ui:
                    mods_for_cls = models_by_class.get(cls_item, [])
                    if not mods_for_cls: st.warning(f"'{cls_item}'ã«å¯¾å¿œã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãªã—"); continue
                    mod_opts = [f"{m['model_name']} ({m['model_type']})" for m in mods_for_cls]
                    def_idx = next((i for i, m in enumerate(mods_for_cls) if m.get("car_class") == cls_item), 0)
                    c1, c2 = st.columns([2,3])
                    with c1: st.markdown(f"**{cls_item}**")
                    with c2:
                        sel_mod_idx = st.selectbox(f"ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", range(len(mod_opts)), format_func=lambda i: mod_opts[i], index=def_idx, key=f"sel_mod_{cls_item}")
                        models_for_run[cls_item] = mods_for_cls[sel_mod_idx]
                        if "metrics" in models_for_run[cls_item]: 
                            metrics_disp = models_for_run[cls_item]["metrics"]
                            metric_str_disp = ", ".join([f"{k}: {v:.4f}" for k, v in metrics_disp.items() if k in ["RMSE", "R2"]])
                            st.caption(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {models_for_run[cls_item].get('row_count', 'ä¸æ˜')}è¡Œ, {metric_str_disp}")
                st.subheader("é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ä¸€è¦§")
                display_model_data = []
                for cls, model_detail in models_for_run.items():
                    row = {"è»Šä¸¡ã‚¯ãƒ©ã‚¹": cls, "ãƒ¢ãƒ‡ãƒ«å": model_detail.get("model_name", "N/A"), "ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—": model_detail.get("model_type", "N/A")}
                    metrics = model_detail.get("metrics", {})
                    row["RMSE"] = metrics.get("RMSE", "N/A")
                    row["R2"] = metrics.get("R2", "N/A")
                    row["å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è¡Œæ•°"] = model_detail.get("row_count", "N/A")
                    display_model_data.append(row)
                if display_model_data: st.dataframe(pd.DataFrame(display_model_data))

            else: st.warning("è»Šä¸¡ã‚¯ãƒ©ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„")
        else: st.error(f"'{CAR_CLASS_COLUMN}'åˆ—ãªã—")

    with st.expander("å®Ÿè¡Œè¨­å®š", expanded=True):
        max_workers_val = st.slider("ä¸¦åˆ—å‡¦ç†æ•°", 1, (os.cpu_count() or 1), min(4, (os.cpu_count() or 1)), key="batch_max_workers")
        combinations = len(date_range) * len(models_for_run)
        st.info(f"å‡¦ç†äºˆå®š: {combinations}ä»¶ (æ—¥ä»˜{len(date_range)}Ã—ã‚¯ãƒ©ã‚¹{len(models_for_run)})")
        estimated_time_sec = combinations * 1.5 / max_workers_val
        st.warning(f"å‡¦ç†æ™‚é–“ç›®å®‰: ç´„ {estimated_time_sec:.1f}ç§’ï¼ˆ{estimated_time_sec/60:.1f}åˆ†ï¼‰")
        save_locally_flag = st.checkbox("çµæœã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜", True, key="batch_save_local")
    
    if date_range and models_for_run and st.button("ğŸš€ ãƒãƒƒãƒåˆ†æã‚’å®Ÿè¡Œ", key="batch_run_main_btn"):
        st.markdown("---"); st.header("ãƒãƒƒãƒåˆ†æçµæœ")
        if date_range: 
            min_display_date = min(date_range)
            max_display_date = max(date_range)
            st.subheader(f"åˆ†ææœŸé–“: {min_display_date}{' ã€œ ' + str(max_display_date) if min_display_date != max_display_date else ''}")
        
        with st.spinner('ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œä¸­...'):
            loaded_models_dict = {}
            loaded_metadata_dict = {}
            for cls_run, model_info_run in models_for_run.items():
                lm = load_model(model_info_run["path"])
                if lm: loaded_models_dict[cls_run] = lm
                else: st.error(f"{cls_run}ã®ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¤±æ•—"); continue 
                if "filename" in model_info_run: loaded_metadata_dict[cls_run] = get_model_metadata(model_info_run["filename"])
            
            if not loaded_models_dict: st.error("å®Ÿè¡Œå¯èƒ½ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"); return

            actual_car_classes_to_run = list(loaded_models_dict.keys())
            _, result_metadata_list = run_batch_prediction(
                data, loaded_models_dict, date_range, actual_car_classes_to_run, loaded_metadata_dict, max_workers_val
            )
            
            display_data_tuple = display_batch_results_in_page(result_metadata_list, return_figures=True)
            
            if save_locally_flag and display_data_tuple:
                df_res, fig_d_res, fig_c_res, df_date_rev_res, df_class_rev_res = display_data_tuple
                if df_res is not None: 
                    save_batch_results_to_folder(
                        result_metadata_list, df_date_rev_res, df_class_rev_res, df_res, fig_d_res, fig_c_res
                    )
    st.markdown("---"); st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"); st.dataframe(data.head()) 