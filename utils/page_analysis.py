# utils/page_analysis.py

import streamlit as st
import pandas as pd
import datetime # ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«åç”¨ã«è¿½åŠ 
from .constants import ( # constants ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    USAGE_COUNT_COLUMN, TARGET_VARIABLE, BOOKING_DATE_COLUMN,
    LAG_TARGET_COLUMN, LAG_DAYS, LAG_GROUP_COLS
)
from .data_processing import ( # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤‰æ›´
    display_exploration,
    recalculate_lag_feature # ãƒ©ã‚°å†è¨ˆç®—é–¢æ•°
)
from .ui_components import ( # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤‰æ›´
    render_data_analysis_sidebar_widgets
)
from .analysis import analyze_daily_sum_after_date # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤‰æ›´
from .data_modification import nullify_usage_data_after_date # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤‰æ›´

# --- ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»ä¿®æ­£ãƒšãƒ¼ã‚¸æç”»é–¢æ•° ---
def render_data_analysis_page(data: pd.DataFrame):
    st.title("ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»ä¿®æ­£")

    # --- å‰å›ã®æ›´æ–°ã‚µãƒãƒªãƒ¼è¡¨ç¤º --- #
    if 'last_update_summary' in st.session_state and st.session_state['last_update_summary']:
        summary = st.session_state['last_update_summary']
        st.markdown("---")
        st.subheader("å‰å›ã®ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒ»å†è¨ˆç®—çµæœ")
        if summary.get("status") == "success":
            # â˜…â˜…â˜… Nullify ã¨ Lag ã®ä¸¡æ–¹ã®çµæœã‚’è¡¨ç¤º â˜…â˜…â˜…
            nullify_res = summary.get("nullify_result", {})
            lag_res = summary.get("lag_recalc_result", {})

            success_messages = []
            if nullify_res.get("count") is not None: # count ãŒ 0 ã§ã‚‚è¡¨ç¤º
                 if nullify_res.get("count", 0) > 0:
                     success_messages.append(
                         f"**{summary.get('date', 'ä¸æ˜')}**ä»¥é™ã®**{nullify_res.get('count', 0)}è¡Œ**ã§åˆ—**{nullify_res.get('cols', [])}**ã‚’NAã«æ›´æ–°ã€‚"
                     )
                 else:
                     success_messages.append(
                         f"**{summary.get('date', 'ä¸æ˜')}**ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿æ›´æ–°å¯¾è±¡ãªã—ã€‚"
                     )

            if lag_res:
                 success_messages.append(
                     f"ãƒ©ã‚°ç‰¹å¾´é‡**'{lag_res.get('lag_col_name', '?')}'**ã‚’å†è¨ˆç®—({lag_res.get('nan_count', '?')}è¡ŒNaN)ã€‚"
                 )

            if success_messages:
                 st.success("âœ… " + " ".join(success_messages))
            else:
                 st.info("â„¹ï¸ ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒ»å†è¨ˆç®—å‡¦ç†ã¯å®Ÿè¡Œã•ã‚Œã¾ã—ãŸãŒã€å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        else: # status ãŒ 'error' ã¾ãŸã¯ä¸æ˜ãªå ´åˆ
             st.warning(f"âš ï¸ å‰å›ã®å‡¦ç†ã§å•é¡ŒãŒç™ºç”Ÿ: {summary.get('message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")

        del st.session_state['last_update_summary']
        st.markdown("---")

    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ --- #
    selected_analysis_date, analyze_button = render_data_analysis_sidebar_widgets(data)

    # --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ --- #
    st.header("ãƒ‡ãƒ¼ã‚¿æ¢ç´¢")
    display_exploration(data)

    # --- æ—¥åˆ¥åˆè¨ˆã‚°ãƒ©ãƒ•è¡¨ç¤º & ã‚¼ãƒ­æ—¥ä»˜ç‰¹å®š --- #
    st.header(f"ç‰¹å®šäºˆç´„æ—¥ä»¥é™ã® '{USAGE_COUNT_COLUMN}' æ—¥åˆ¥åˆè¨ˆæ¨ç§»")
    st.write(f"æŒ‡å®šã—ãŸæ—¥ä»˜ã‚ˆã‚Š**å¾Œ**ã®äºˆç´„æ—¥ã«ã¤ã„ã¦ã€æ—¥ã”ã¨ã® '{USAGE_COUNT_COLUMN}' ã®åˆè¨ˆå€¤ã‚’ã‚°ãƒ©ãƒ•è¡¨ç¤ºã—ã¾ã™ã€‚")
    if selected_analysis_date is not None:
        daily_sum_df = analyze_daily_sum_after_date(data=data, start_date=selected_analysis_date, booking_date_col=BOOKING_DATE_COLUMN, sum_col=USAGE_COUNT_COLUMN)
        if daily_sum_df is not None:
            if not daily_sum_df.empty:
                st.line_chart(daily_sum_df)
                zero_date_str = None
                daily_sum_df_sorted = daily_sum_df.sort_index()
                sum_col_name = f'{USAGE_COUNT_COLUMN}_åˆè¨ˆ'
                if sum_col_name in daily_sum_df_sorted.columns:
                     zero_rows = daily_sum_df_sorted[daily_sum_df_sorted[sum_col_name] <= 0]
                     if not zero_rows.empty:
                         zero_date_str = zero_rows.index[0].strftime('%Y-%m-%d')
                         st.info(f"ğŸ“ˆã‚°ãƒ©ãƒ•ã®å€¤ãŒæœ€åˆã«0ã«ãªã£ãŸæ—¥ä»˜: **{zero_date_str}**")
                         st.session_state['zero_cutoff_date'] = zero_date_str
                     else:
                         st.info("ğŸ“ˆã‚°ãƒ©ãƒ•æœŸé–“ä¸­ã«å€¤ãŒ0ã«ãªã‚‹æ—¥ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                         if 'zero_cutoff_date' in st.session_state: del st.session_state['zero_cutoff_date']
                else: st.warning("ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆè¨ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                with st.expander("è©³ç´°ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º"):
                     st.dataframe(daily_sum_df)
    else:
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§èµ·ç‚¹ã¨ãªã‚‹äºˆç´„æ—¥ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

    # --- ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã¨ãƒ©ã‚°å†è¨ˆç®—ã‚»ã‚¯ã‚·ãƒ§ãƒ³ --- #
    st.markdown("---")
    st.header("ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã¨ãƒ©ã‚°ç‰¹å¾´é‡å†è¨ˆç®—")
    if 'zero_cutoff_date' in st.session_state and st.session_state['zero_cutoff_date']:
        cutoff_date_str = st.session_state['zero_cutoff_date']
        st.write(f"ç‰¹å®šã•ã‚ŒãŸæ—¥ä»˜ **{cutoff_date_str}** ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã€")
        st.write(f"'{USAGE_COUNT_COLUMN}' ãŠã‚ˆã³ '{TARGET_VARIABLE}' ã‚’æ¬ æå€¤(NA)ã«æ›´æ–°ã—ã€")
        st.write(f"'{LAG_TARGET_COLUMN}_lag{LAG_DAYS}' ã‚’å†è¨ˆç®—ã—ã¾ã™ã€‚")
        update_button = st.button(f"ğŸ”„ {cutoff_date_str} ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼†ãƒ©ã‚°å†è¨ˆç®—", key="update_data_button")
        if update_button:
            update_status = "error"
            update_message = ""
            nullify_result = None
            lag_recalc_result = None
            with st.spinner("ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã¨ãƒ©ã‚°å†è¨ˆç®—ã‚’å®Ÿè¡Œä¸­..."):
                try:
                    current_data = st.session_state.get('processed_data')
                    if current_data is None:
                         update_message = "ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
                         st.error(f"ã‚¨ãƒ©ãƒ¼: {update_message}")
                         st.stop()
                    cutoff_date = pd.to_datetime(cutoff_date_str).date()
                    cols_to_null = [USAGE_COUNT_COLUMN, TARGET_VARIABLE]
                    data_nulled, num_rows_updated, updated_cols = nullify_usage_data_after_date(
                        df=current_data.copy(), cutoff_date=cutoff_date, date_col=BOOKING_DATE_COLUMN, cols_to_nullify=cols_to_null
                    )
                    nullify_result = {"count": num_rows_updated, "cols": updated_cols}
                    if data_nulled is not None and num_rows_updated is not None:
                        data_recalculated, lag_info = recalculate_lag_feature(
                            df_processed=data_nulled, lag_target_col=LAG_TARGET_COLUMN, lag_days=LAG_DAYS,
                            booking_date_col=BOOKING_DATE_COLUMN, group_cols=LAG_GROUP_COLS
                        )
                        lag_recalc_result = lag_info
                        if data_recalculated is not None and isinstance(data_recalculated, pd.DataFrame):
                            st.session_state['processed_data'] = data_recalculated
                            update_status = "success"
                        else: update_message = "ãƒ©ã‚°ç‰¹å¾´é‡ã®å†è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
                    else: update_message = "ãƒ‡ãƒ¼ã‚¿æ›´æ–°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
                except Exception as e_update: update_message = f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_update}"
                st.session_state['last_update_summary'] = {
                    "status": update_status, "message": update_message, "date": cutoff_date_str,
                    "nullify_result": nullify_result, "lag_recalc_result": lag_recalc_result
                }
                if 'zero_cutoff_date' in st.session_state: del st.session_state['zero_cutoff_date']
            st.rerun()
    else:
        st.info("å…ˆã«ä¸Šè¨˜ã®ã€Œæ—¥åˆ¥åˆè¨ˆæ¨ç§»ã€ã®åˆ†æã‚’å®Ÿè¡Œã—ã€ã‚°ãƒ©ãƒ•ãŒ0ã«ãªã‚‹æ—¥ä»˜ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚")

    # --- åˆ—å‰Šé™¤ã‚»ã‚¯ã‚·ãƒ§ãƒ³ --- #
    st.markdown("---")
    st.header("åˆ—ã®å‰Šé™¤")
    st.write("ä¸è¦ãªåˆ—ã‚’é¸æŠã—ã¦å‰Šé™¤ã§ãã¾ã™ã€‚")
    current_data_cols = data.columns.tolist()
    cols_to_delete = st.multiselect(
        "å‰Šé™¤ã™ã‚‹åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„:",
        options=current_data_cols,
        key="delete_columns_multiselect"
    )
    delete_cols_button = st.button("ğŸ—‘ï¸ é¸æŠã—ãŸåˆ—ã‚’å‰Šé™¤", key="delete_columns_button")
    if delete_cols_button and cols_to_delete:
        with st.spinner("åˆ—ã‚’å‰Šé™¤ä¸­..."):
            try:
                current_data = st.session_state.get('processed_data')
                if current_data is not None:
                    data_after_delete = current_data.drop(columns=cols_to_delete)
                    st.session_state['processed_data'] = data_after_delete
                    st.success(f"åˆ— {cols_to_delete} ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                    st.rerun()
                else:
                    st.error("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            except KeyError as e:
                 st.error(f"åˆ—ã®å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: å­˜åœ¨ã—ãªã„åˆ— {e} ãŒæŒ‡å®šã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            except Exception as e:
                 st.error(f"åˆ—ã®å‰Šé™¤ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    elif delete_cols_button and not cols_to_delete:
         st.warning("å‰Šé™¤ã™ã‚‹åˆ—ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # â˜…â˜…â˜… ã“ã“ã«ç§»å‹• â˜…â˜…â˜…
    st.markdown("---")
    st.header("è¡Œã®å‰Šé™¤ï¼ˆæ¬ æå€¤åŸºæº–ï¼‰")
    st.write("æŒ‡å®šã—ãŸåˆ—ã«æ¬ æå€¤(NaN)ãŒå«ã¾ã‚Œã‚‹è¡Œã‚’å‰Šé™¤ã—ã¾ã™ã€‚")
    current_data_cols_for_nan_check = data.columns.tolist()
    cols_to_check_for_nan = st.multiselect(
        "æ¬ æå€¤(NaN)ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„:",
        options=current_data_cols_for_nan_check,
        key="nan_check_columns_multiselect"
    )
    delete_nan_rows_button = st.button("ğŸ§¹ é¸æŠåˆ—ã®NaNè¡Œã‚’å‰Šé™¤", key="delete_nan_rows_button")
    if delete_nan_rows_button and cols_to_check_for_nan:
        with st.spinner("NaNã‚’å«ã‚€è¡Œã‚’å‰Šé™¤ä¸­..."):
            try:
                current_data_nan = st.session_state.get('processed_data')
                if current_data_nan is not None:
                    rows_before_drop = len(current_data_nan)
                    nan_rows_mask = current_data_nan[cols_to_check_for_nan].isnull().any(axis=1)
                    deleted_nan_rows = None
                    if nan_rows_mask.any():
                        deleted_nan_rows = current_data_nan[nan_rows_mask].copy()
                    data_after_drop_nan = current_data_nan.dropna(subset=cols_to_check_for_nan)
                    rows_after_drop = len(data_after_drop_nan)
                    rows_removed = rows_before_drop - rows_after_drop
                    st.session_state['processed_data'] = data_after_drop_nan
                    st.success(f"åˆ— {cols_to_check_for_nan} ã®ã„ãšã‚Œã‹ã«NaNã‚’å«ã‚€ {rows_removed} è¡Œã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                    if deleted_nan_rows is not None and not deleted_nan_rows.empty:
                         with st.expander(f"å‰Šé™¤ã•ã‚ŒãŸ {rows_removed} è¡Œã®è©³ç´°ã‚’è¡¨ç¤º"):
                              st.dataframe(deleted_nan_rows)
                    # st.rerun() # ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆç¶™ç¶š
                else:
                    st.error("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            except KeyError as e:
                 st.error(f"NaNè¡Œã®å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: å­˜åœ¨ã—ãªã„åˆ— {e} ãŒæŒ‡å®šã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            except Exception as e:
                 st.error(f"NaNè¡Œã®å‰Šé™¤ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    elif delete_nan_rows_button and not cols_to_check_for_nan:
         st.warning("NaNã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹åˆ—ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # --- ä¿®æ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³ --- #
    st.markdown("---")
    st.header("ä¿®æ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜")
    st.write("ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®çŠ¶æ…‹ï¼ˆãƒ‡ãƒ¼ã‚¿æ›´æ–°ã€åˆ—å‰Šé™¤ãªã©ï¼‰ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚")

    # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    current_data_to_save = st.session_state.get('processed_data')

    if current_data_to_save is not None and isinstance(current_data_to_save, pd.DataFrame):
        try:
            csv_data = current_data_to_save.to_csv(index=False).encode('utf-8')
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆå…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åãŒã‚ã‚Œã°ä½¿ã†ã€ãªã‘ã‚Œã°ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰
            original_filename = st.session_state.get('last_uploaded_filename', 'data')
            if original_filename.endswith('.csv'):
                original_filename_base = original_filename[:-4]
            else:
                original_filename_base = original_filename
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            download_filename = f"{original_filename_base}_modified_{timestamp}.csv"

            st.download_button(
                label="ğŸ’¾ ä¿®æ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’CSVã¨ã—ã¦ä¿å­˜",
                data=csv_data,
                file_name=download_filename,
                mime='text/csv',
                key='download_modified_data_button'
            )
        except Exception as e:
            st.error(f"CSVãƒ‡ãƒ¼ã‚¿ã¸ã®å¤‰æ›ã¾ãŸã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    elif current_data_to_save is None:
         st.warning("ä¿å­˜å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
         st.warning("ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒäºˆæœŸã›ã¬å½¢å¼ã§ã™ã€‚") 