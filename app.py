# app.py å®Œæˆç‰ˆ (ãƒ‡ãƒ¼ã‚¿æ›´æ–°æ©Ÿèƒ½ãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆå¯¾å¿œ)

import streamlit as st
import pandas as pd
import os
import yaml
import datetime
import numpy as np # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ç”¨ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from utils.data_processing import (
    load_data, preprocess_data, display_exploration, filter_data_by_date,
    create_scenario_data, find_last_price_change_lead_time,
    recalculate_lag_feature # ãƒ©ã‚°å†è¨ˆç®—é–¢æ•°
)
from utils.visualization import (
    plot_booking_curve, plot_price_trends, plot_comparison_curve,
    plot_feature_importance
)
from utils.modeling import (
    setup_and_compare_models, predict_with_model, get_feature_importance_df
)
from utils.ui_components import (
    render_prediction_sidebar_widgets, render_data_analysis_sidebar_widgets
)
from utils.analysis import analyze_unique_count_after_date, analyze_daily_sum_after_date
from utils.data_modification import nullify_usage_data_after_date # ãƒ‡ãƒ¼ã‚¿æ›´æ–°é–¢æ•°

# --- å®šæ•° ---
TARGET_VARIABLE = 'åˆ©ç”¨å°æ•°ç´¯ç©'
DATE_COLUMN = 'åˆ©ç”¨æ—¥'
PRICE_COLUMNS = ['ä¾¡æ ¼_ãƒˆãƒ¨ã‚¿', 'ä¾¡æ ¼_ã‚ªãƒªãƒƒã‚¯ã‚¹']
LEAD_TIME_COLUMN = 'ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ _è¨ˆç®—æ¸ˆ'
CAR_CLASS_COLUMN = 'è»Šä¸¡ã‚¯ãƒ©ã‚¹'
BOOKING_DATE_COLUMN = 'äºˆç´„æ—¥'
USAGE_COUNT_COLUMN = 'åˆ©ç”¨å°æ•°'
LAG_TARGET_COLUMN = 'åˆ©ç”¨å°æ•°ç´¯ç©' # ãƒ©ã‚°è¨ˆç®—ã®å¯¾è±¡åˆ—
LAG_DAYS = 30 # ãƒ©ã‚°æ—¥æ•°
LAG_GROUP_COLS = [DATE_COLUMN, CAR_CLASS_COLUMN] # ãƒ©ã‚°è¨ˆç®—æ™‚ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–åˆ—

# --- è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•° ---
def load_config(config_path='config.yaml'):
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config.get('model_config', {})
    except FileNotFoundError:
        return {}
    except Exception as e:
        st.sidebar.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

# --- äºˆæ¸¬ãƒ»æ¯”è¼ƒåˆ†æãƒšãƒ¼ã‚¸æç”»é–¢æ•° ---
def render_prediction_analysis_page(data: pd.DataFrame, config: dict):
    st.title("äºˆæ¸¬ãƒ»æ¯”è¼ƒåˆ†æ")

    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®æç”»ã¨å€¤ã®å–å¾— ---
    (
        selected_car_class,
        selected_date,
        selected_numeric,
        selected_categorical,
        selected_features,
        models_to_compare,
        run_analysis
    ) = render_prediction_sidebar_widgets(data, config)

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ --- #
    st.subheader("å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ç¾åœ¨ã®çŠ¶æ…‹)")
    st.dataframe(data.head())
    # ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã¯åˆ¥ãƒšãƒ¼ã‚¸

    st.markdown("---") # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨çµæœã®é–“ã«åŒºåˆ‡ã‚Š

    if selected_date is not None:
        st.header(f"åˆ†æçµæœ: {selected_date} ({selected_car_class})")

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if selected_car_class == "å…¨ã‚¯ãƒ©ã‚¹":
            data_class_filtered_for_viz = data
        else:
            data_class_filtered_for_viz = data[data[CAR_CLASS_COLUMN] == selected_car_class]

        data_filtered = filter_data_by_date(data_class_filtered_for_viz, DATE_COLUMN, selected_date)

        if not data_filtered.empty:
            if LEAD_TIME_COLUMN in data_filtered.columns:
                data_filtered_sorted = data_filtered.sort_values(by=LEAD_TIME_COLUMN)

                # å®Ÿéš›ã®äºˆç´„æ›²ç·šã¨ä¾¡æ ¼æ¨ç§»ã‚°ãƒ©ãƒ•
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("å®Ÿéš›ã®äºˆç´„æ›²ç·š")
                    fig_actual = plot_booking_curve(data_filtered_sorted, x_col=LEAD_TIME_COLUMN, y_col=TARGET_VARIABLE, title=f"{selected_date} {selected_car_class} å®Ÿéš›ã®äºˆç´„æ›²ç·š")
                    st.plotly_chart(fig_actual, use_container_width=True)
                with col2:
                    st.subheader("ä¾¡æ ¼æ¨ç§»")
                    fig_prices = plot_price_trends(data_filtered_sorted, x_col=LEAD_TIME_COLUMN, y_cols=PRICE_COLUMNS, title=f"{selected_date} {selected_car_class} ä¾¡æ ¼æ¨ç§»")
                    st.plotly_chart(fig_prices, use_container_width=True)

                # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã¨äºˆæ¸¬ã®å®Ÿè¡Œ
                if run_analysis:
                    st.markdown("---")
                    st.header("ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨äºˆæ¸¬æ¯”è¼ƒ")
                    with st.spinner('ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã¨äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­...'):
                        data_for_modeling = data[data[CAR_CLASS_COLUMN] == selected_car_class] if selected_car_class != "å…¨ã‚¯ãƒ©ã‚¹" else data

                        with st.expander("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã«ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º"):
                            columns_to_show = selected_features.copy()
                            if TARGET_VARIABLE not in columns_to_show:
                                columns_to_show.append(TARGET_VARIABLE)

                            lag_col_name = f"{LAG_TARGET_COLUMN}_lag{LAG_DAYS}"
                            if lag_col_name in data_for_modeling.columns and lag_col_name not in columns_to_show:
                                columns_to_show.append(lag_col_name)

                            existing_columns_to_show = [col for col in columns_to_show if col in data_for_modeling.columns]
                            if pd.Series(existing_columns_to_show).duplicated().any():
                                existing_columns_to_show = pd.Series(existing_columns_to_show).drop_duplicates().tolist()

                            if existing_columns_to_show:
                                st.dataframe(data_for_modeling[existing_columns_to_show].head())
                            else:
                                st.warning("è¡¨ç¤ºã™ã‚‹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

                        # ç„¡è¦–ãƒªã‚¹ãƒˆç”Ÿæˆ (potential_features ã®å†å®šç¾©ã‚‚ã“ã“ã§è¡Œã†)
                        potential_features = [col for col in data.columns if col not in [
                            TARGET_VARIABLE, DATE_COLUMN, BOOKING_DATE_COLUMN, LEAD_TIME_COLUMN, 'ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ', USAGE_COUNT_COLUMN
                        ]]
                        all_numeric_cols = data_for_modeling[potential_features].select_dtypes(include=['number']).columns.tolist()
                        all_category_cols = data_for_modeling[potential_features].select_dtypes(exclude=['number', 'datetime', 'timedelta']).columns.tolist()
                        ignored_numeric = list(set(all_numeric_cols) - set(selected_numeric))
                        ignored_categorical = list(set(all_category_cols) - set(selected_categorical))
                        # â˜…â˜…â˜… 'åˆ©ç”¨å°æ•°ç´¯ç©_lag30' ã‚’å‰Šé™¤ â˜…â˜…â˜…
                        explicitly_ignored = ['æ›œæ—¥_name', 'en_name'] # lag30 ã¯é¸æŠã•ã‚Œãªã‘ã‚Œã°ç„¡è¦–ã•ã‚Œã‚‹
                        final_ignore_features = list(set(ignored_numeric + ignored_categorical + explicitly_ignored))

                        # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
                        best_model, comparison_results, setup_result = setup_and_compare_models(
                            _data=data_for_modeling, target=TARGET_VARIABLE,
                            numeric_features=selected_numeric, categorical_features=selected_categorical,
                            ignore_features=final_ignore_features, include_models=models_to_compare,
                            sort_metric='RMSE'
                        )

                        if best_model is not None and setup_result is not None:
                            st.markdown("---")
                            st.subheader(f"æœ€è‰¯ãƒ¢ãƒ‡ãƒ« ({type(best_model).__name__}) ã®ç‰¹å¾´é‡é‡è¦åº¦")
                            importance_df = get_feature_importance_df(best_model, setup_result)
                            if importance_df is not None and not importance_df.empty:
                                fig_importance = plot_feature_importance(importance_df)
                                if fig_importance: st.plotly_chart(fig_importance, use_container_width=True)
                                with st.expander("ç‰¹å¾´é‡é‡è¦åº¦ãƒ‡ãƒ¼ã‚¿"): st.dataframe(importance_df)
                            else: st.info("ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

                            # ã‚·ãƒŠãƒªã‚ªäºˆæ¸¬
                            last_change_lt = find_last_price_change_lead_time(data_filtered_sorted, PRICE_COLUMNS, LEAD_TIME_COLUMN)
                            if last_change_lt is not None:
                                st.write(f"ä¾¡æ ¼æœ€çµ‚å¤‰æ›´ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ : {last_change_lt}")
                                data_scenario = create_scenario_data(
                                    data_filtered_sorted, PRICE_COLUMNS, LEAD_TIME_COLUMN,
                                    scenario_type='last_change_fixed', change_lead_time=last_change_lt
                                )
                                scenario_title_suffix = f"ä¾¡æ ¼æœ€çµ‚å¤‰æ›´ç‚¹(LT={last_change_lt})å›ºå®šã‚·ãƒŠãƒªã‚ª"

                                if not data_scenario.empty:
                                    with st.expander(f"äºˆæ¸¬ã«ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ ({scenario_title_suffix}) ã®ã‚µãƒ³ãƒ—ãƒ«"):
                                        # â˜…â˜…â˜… åˆæœŸãƒªã‚¹ãƒˆã‚’ selected_features ã®ã‚³ãƒ”ãƒ¼ã§é–‹å§‹ â˜…â˜…â˜…
                                        display_columns = selected_features.copy()
                                        # å¿…é ˆåˆ—ã‚’è¿½åŠ  (é‡è¤‡ã—ãªã„ã‚ˆã†ã«ãƒã‚§ãƒƒã‚¯)
                                        essential_columns = [LEAD_TIME_COLUMN, TARGET_VARIABLE] + PRICE_COLUMNS
                                        for col in essential_columns:
                                            if col in data_scenario.columns and col not in display_columns:
                                                display_columns.append(col)
                                        # ãƒ©ã‚°åˆ—åã‚’è¿½åŠ  (é‡è¤‡ã—ãªã„ã‚ˆã†ã«ãƒã‚§ãƒƒã‚¯)
                                        lag_col_name = f"{LAG_TARGET_COLUMN}_lag{LAG_DAYS}"
                                        # â˜…â˜…â˜… é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ  â˜…â˜…â˜…
                                        if lag_col_name in data_scenario.columns and lag_col_name not in display_columns:
                                             display_columns.append(lag_col_name)

                                        # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° & æœ€çµ‚é‡è¤‡å‰Šé™¤
                                        existing_display_columns = [col for col in display_columns if col in data_scenario.columns]
                                        if pd.Series(existing_display_columns).duplicated().any():
                                            existing_display_columns = pd.Series(existing_display_columns).drop_duplicates().tolist()

                                        if existing_display_columns:
                                            try:
                                                # â˜…â˜…â˜… ã‚¨ãƒ©ãƒ¼ç®‡æ‰€ â˜…â˜…â˜…
                                                st.dataframe(data_scenario[existing_display_columns].head())
                                                csv = data_scenario[existing_display_columns].to_csv(index=False).encode('utf-8')
                                                filename = f"scenario_data_{selected_date}_{selected_car_class}_{scenario_title_suffix.replace(' ', '_')}.csv"
                                                st.download_button("ğŸ’¾ äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, filename, "text/csv")
                                            except ValueError as e:
                                                 st.error(f"ã‚·ãƒŠãƒªã‚ªãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                                                 st.write("è¡¨ç¤ºã—ã‚ˆã†ã¨ã—ãŸåˆ—:", existing_display_columns)
                                        else:
                                            st.warning("è¡¨ç¤ºåˆ—ãªã—")

                                    predictions = predict_with_model(best_model, data_scenario)
                                    if not predictions.empty:
                                        # çµæœè¡¨ç¤º
                                        st.markdown("---")
                                        col_m1, col_m2 = st.columns(2)
                                        with col_m1:
                                            st.subheader("ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æ¯”è¼ƒçµæœ")
                                            st.dataframe(comparison_results)
                                        with col_m2:
                                            st.subheader(f"å®Ÿç¸¾ vs äºˆæ¸¬æ¯”è¼ƒ ({scenario_title_suffix}) - LT {last_change_lt} ä»¥é™")
                                            actual_filtered_display = data_filtered_sorted[data_filtered_sorted[LEAD_TIME_COLUMN] <= last_change_lt]
                                            if LEAD_TIME_COLUMN not in predictions.columns:
                                                predictions_with_lt = pd.merge(predictions, data_scenario[[LEAD_TIME_COLUMN]], left_index=True, right_index=True, how='left')
                                            else:
                                                predictions_with_lt = predictions
                                            predictions_filtered_display = predictions_with_lt[predictions_with_lt[LEAD_TIME_COLUMN] <= last_change_lt]

                                            if not actual_filtered_display.empty and not predictions_filtered_display.empty:
                                                fig_compare = plot_comparison_curve(
                                                    df_actual=actual_filtered_display, df_predicted=predictions_filtered_display,
                                                    x_col=LEAD_TIME_COLUMN, y_actual_col=TARGET_VARIABLE, y_pred_col='prediction_label',
                                                    title=f"{selected_date} {selected_car_class} å®Ÿç¸¾ vs äºˆæ¸¬ (LT {last_change_lt} ä»¥é™)"
                                                )
                                                st.plotly_chart(fig_compare, use_container_width=True)

                                                st.subheader(f"å®Ÿç¸¾ vs äºˆæ¸¬ ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ« (LT {last_change_lt} ä»¥é™)")
                                                df_actual_for_table = actual_filtered_display[[LEAD_TIME_COLUMN, TARGET_VARIABLE]].rename(columns={TARGET_VARIABLE: 'å®Ÿç¸¾åˆ©ç”¨å°æ•°'})
                                                df_pred_for_table = predictions_filtered_display[[LEAD_TIME_COLUMN, 'prediction_label']].rename(columns={'prediction_label': 'äºˆæ¸¬åˆ©ç”¨å°æ•°'})
                                                df_comparison_table = pd.merge(df_actual_for_table, df_pred_for_table, on=LEAD_TIME_COLUMN, how='inner')
                                                st.dataframe(df_comparison_table.sort_values(by=LEAD_TIME_COLUMN).reset_index(drop=True))
                                            else:
                                                st.warning(f"LT {last_change_lt} ä»¥é™ã®è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿ãªã—")
                                    else:
                                        st.error("äºˆæ¸¬å®Ÿè¡Œå¤±æ•—")
                                else:
                                    st.error("ã‚·ãƒŠãƒªã‚ªãƒ‡ãƒ¼ã‚¿ä½œæˆå¤±æ•—")
                            else:
                                st.warning("ä¾¡æ ¼å¤‰å‹•ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€æœ€çµ‚ä¾¡æ ¼å›ºå®šã‚·ãƒŠãƒªã‚ªã§ã®äºˆæ¸¬ã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
                        elif best_model is None:
                            st.error("ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒå¤±æ•—")
                        else:
                            st.error("PyCaretã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å¤±æ•—")
            else:
                st.warning(f"'{LEAD_TIME_COLUMN}'åˆ—ãªã—")
        else:
             st.info(f"'{selected_date}' ({selected_car_class}) ã®ãƒ‡ãƒ¼ã‚¿ãªã—")
    elif selected_date is None:
        # ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šåˆ©ç”¨æ—¥åˆ—ã‚‚ã‚ã‚‹ãŒæ—¥ä»˜æœªé¸æŠã®å ´åˆ
        if DATE_COLUMN in data.columns and pd.api.types.is_datetime64_any_dtype(data[DATE_COLUMN]) and not data[DATE_COLUMN].isnull().all():
             st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰åˆ†æã—ãŸã„åˆ©ç”¨æ—¥ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

# --- ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»ä¿®æ­£ãƒšãƒ¼ã‚¸æç”»é–¢æ•° ---
def render_data_analysis_page(data: pd.DataFrame):
    st.title("ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»ä¿®æ­£")

    # --- å‰å›ã®æ›´æ–°ã‚µãƒãƒªãƒ¼è¡¨ç¤º --- #
    if 'last_update_summary' in st.session_state and st.session_state['last_update_summary']:
        summary = st.session_state['last_update_summary']
        st.markdown("---")
        st.subheader("å‰å›ã®ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒ»å†è¨ˆç®—çµæœ")
        if summary.get("status") == "success":
            # â˜…â˜…â˜… Nullify ã¨ Lag ã®ä¸¡æ–¹ã®çµæœã‚’è¡¨ç¤º â˜…â˜…â˜…
            nullify_res = summary.get("nullify_result", {})
            lag_res = summary.get("lag_recalc_result", {})

            success_messages = []
            if nullify_res.get("count") is not None: # count ãŒ 0 ã§ã‚‚è¡¨ç¤º
                 if nullify_res.get("count", 0) > 0:
                     success_messages.append(
                         f"**{summary.get('date', 'ä¸æ˜')}**ä»¥é™ã®**{nullify_res.get('count', 0)}è¡Œ**ã§åˆ—**{nullify_res.get('cols', [])}**ã‚’NAã«æ›´æ–°ã€‚"
                     )
                 else:
                     success_messages.append(
                         f"**{summary.get('date', 'ä¸æ˜')}**ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿æ›´æ–°å¯¾è±¡ãªã—ã€‚"
                     )

            if lag_res:
                 success_messages.append(
                     f"ãƒ©ã‚°ç‰¹å¾´é‡**'{lag_res.get('lag_col_name', '?')}'**ã‚’å†è¨ˆç®—({lag_res.get('nan_count', '?')}è¡ŒNaN)ã€‚"
                 )

            if success_messages:
                 st.success("âœ… " + " ".join(success_messages))
            else:
                 st.info("â„¹ï¸ ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒ»å†è¨ˆç®—å‡¦ç†ã¯å®Ÿè¡Œã•ã‚Œã¾ã—ãŸãŒã€å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        else: # status ãŒ 'error' ã¾ãŸã¯ä¸æ˜ãªå ´åˆ
             st.warning(f"âš ï¸ å‰å›ã®å‡¦ç†ã§å•é¡ŒãŒç™ºç”Ÿ: {summary.get('message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")

        del st.session_state['last_update_summary']
        st.markdown("---")

    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ ---
    selected_analysis_date, analyze_button = render_data_analysis_sidebar_widgets(data)

    # --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ --- #
    st.header("ãƒ‡ãƒ¼ã‚¿æ¢ç´¢")
    display_exploration(data)
    st.markdown("---")

    st.header(f"ç‰¹å®šäºˆç´„æ—¥ä»¥é™ã® '{USAGE_COUNT_COLUMN}' æ—¥åˆ¥åˆè¨ˆæ¨ç§»")
    st.write(f"æŒ‡å®šã—ãŸæ—¥ä»˜ã‚ˆã‚Š**å¾Œ**ã®äºˆç´„æ—¥ã«ã¤ã„ã¦ã€æ—¥ã”ã¨ã® '{USAGE_COUNT_COLUMN}' ã®åˆè¨ˆå€¤ã‚’ã‚°ãƒ©ãƒ•è¡¨ç¤ºã—ã¾ã™ã€‚")

    # --- æ—¥åˆ¥åˆè¨ˆã‚°ãƒ©ãƒ•è¡¨ç¤º & ã‚¼ãƒ­æ—¥ä»˜ç‰¹å®š --- #
    if selected_analysis_date is not None:
        daily_sum_df = analyze_daily_sum_after_date(data=data, start_date=selected_analysis_date, booking_date_col=BOOKING_DATE_COLUMN, sum_col=USAGE_COUNT_COLUMN)
        if daily_sum_df is not None:
            if not daily_sum_df.empty:
                st.line_chart(daily_sum_df)
                zero_date_str = None
                daily_sum_df_sorted = daily_sum_df.sort_index()
                sum_col_name = f'{USAGE_COUNT_COLUMN}_åˆè¨ˆ'
                if sum_col_name in daily_sum_df_sorted.columns:
                     zero_rows = daily_sum_df_sorted[daily_sum_df_sorted[sum_col_name] <= 0]
                     if not zero_rows.empty:
                         zero_date_str = zero_rows.index[0].strftime('%Y-%m-%d')
                         st.info(f"ğŸ“ˆã‚°ãƒ©ãƒ•ã®å€¤ãŒæœ€åˆã«0ã«ãªã£ãŸæ—¥ä»˜: **{zero_date_str}**")
                         st.session_state['zero_cutoff_date'] = zero_date_str
                     else:
                         st.info("ğŸ“ˆã‚°ãƒ©ãƒ•æœŸé–“ä¸­ã«å€¤ãŒ0ã«ãªã‚‹æ—¥ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                         if 'zero_cutoff_date' in st.session_state: del st.session_state['zero_cutoff_date']
                else: st.warning("ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆè¨ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                with st.expander("è©³ç´°ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º"):
                     st.dataframe(daily_sum_df)
    else:
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§èµ·ç‚¹ã¨ãªã‚‹äºˆç´„æ—¥ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

    # --- ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã¨ãƒ©ã‚°å†è¨ˆç®—ã‚»ã‚¯ã‚·ãƒ§ãƒ³ --- #
    st.markdown("---")
    st.header("ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã¨ãƒ©ã‚°ç‰¹å¾´é‡å†è¨ˆç®—")

    if 'zero_cutoff_date' in st.session_state and st.session_state['zero_cutoff_date']:
        cutoff_date_str = st.session_state['zero_cutoff_date']
        st.write(f"ç‰¹å®šã•ã‚ŒãŸæ—¥ä»˜ **{cutoff_date_str}** ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã€")
        st.write(f"'{USAGE_COUNT_COLUMN}' ãŠã‚ˆã³ '{TARGET_VARIABLE}' ã‚’æ¬ æå€¤(NA)ã«æ›´æ–°ã—ã€")
        st.write(f"'{LAG_TARGET_COLUMN}_lag{LAG_DAYS}' ã‚’å†è¨ˆç®—ã—ã¾ã™ã€‚")

        update_button = st.button(f"ğŸ”„ {cutoff_date_str} ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼†ãƒ©ã‚°å†è¨ˆç®—", key="update_data_button")

        if update_button:
            update_status = "error"
            update_message = ""
            nullify_result = None # Nullifyçµæœç”¨
            lag_recalc_result = None # Lagè¨ˆç®—çµæœç”¨

            with st.spinner("ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã¨ãƒ©ã‚°å†è¨ˆç®—ã‚’å®Ÿè¡Œä¸­..."):
                try:
                    current_data = st.session_state.get('processed_data')
                    if current_data is None:
                         update_message = "ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
                         # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯æœ€å¾Œã«ã¾ã¨ã‚ã¦ã‚µãƒãƒªãƒ¼ã«æ ¼ç´
                         st.error(f"ã‚¨ãƒ©ãƒ¼: {update_message}") # ã“ã“ã§ã¯è¡¨ç¤ºã—ã¦ãŠã
                         st.stop()

                    cutoff_date = pd.to_datetime(cutoff_date_str).date()
                    cols_to_null = [USAGE_COUNT_COLUMN, TARGET_VARIABLE]

                    # 1. ãƒ‡ãƒ¼ã‚¿æ›´æ–°
                    data_nulled, num_rows_updated, updated_cols = nullify_usage_data_after_date(
                        df=current_data.copy(),
                        cutoff_date=cutoff_date,
                        date_col=BOOKING_DATE_COLUMN,
                        cols_to_nullify=cols_to_null
                    )
                    # Nullifyçµæœã‚’ä¿å­˜
                    nullify_result = {"count": num_rows_updated, "cols": updated_cols}

                    if data_nulled is not None and num_rows_updated is not None:
                        # 2. ãƒ©ã‚°ç‰¹å¾´é‡å†è¨ˆç®—
                        # st.info("ãƒ©ã‚°ç‰¹å¾´é‡ã‚’å†è¨ˆç®—ä¸­...") # å†—é•·ãªã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
                        data_recalculated, lag_info = recalculate_lag_feature(
                            df_processed=data_nulled,
                            lag_target_col=LAG_TARGET_COLUMN,
                            lag_days=LAG_DAYS,
                            booking_date_col=BOOKING_DATE_COLUMN,
                            group_cols=LAG_GROUP_COLS
                        )
                        # Lagè¨ˆç®—çµæœã‚’ä¿å­˜
                        lag_recalc_result = lag_info

                        if data_recalculated is not None and isinstance(data_recalculated, pd.DataFrame):
                            st.session_state['processed_data'] = data_recalculated
                            update_status = "success"
                        else:
                            update_message = "ãƒ©ã‚°ç‰¹å¾´é‡ã®å†è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
                    else:
                         update_message = "ãƒ‡ãƒ¼ã‚¿æ›´æ–°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

                except Exception as e_update:
                    update_message = f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_update}"
                    # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã‚‚ã‚µãƒãƒªãƒ¼ã«æƒ…å ±ã‚’æ®‹ã™
                    st.error(f"ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã¾ãŸã¯ãƒ©ã‚°å†è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {update_message}")

                # --- çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜ --- #
                st.session_state['last_update_summary'] = {
                    "status": update_status,
                    "message": update_message,
                    "date": cutoff_date_str,
                    "nullify_result": nullify_result,
                    "lag_recalc_result": lag_recalc_result
                }

                if 'zero_cutoff_date' in st.session_state:
                    del st.session_state['zero_cutoff_date']
                # st.rerun() ã¯å‰Šé™¤æ¸ˆã¿

            # â˜…â˜…â˜… ãƒœã‚¿ãƒ³å‡¦ç†ã®æœ€å¾Œã« st.rerun() ã‚’è¿½åŠ  â˜…â˜…â˜…
            # ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¹ãƒ”ãƒŠãƒ¼ãŒæ¶ˆãˆã€ãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã®ã‚µãƒãƒªãƒ¼è¡¨ç¤ºãŒæ›´æ–°ã•ã‚Œã‚‹
            st.rerun()

    else:
        st.info("å…ˆã«ä¸Šè¨˜ã®ã€Œæ—¥åˆ¥åˆè¨ˆæ¨ç§»ã€ã®åˆ†æã‚’å®Ÿè¡Œã—ã€ã‚°ãƒ©ãƒ•ãŒ0ã«ãªã‚‹æ—¥ä»˜ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚")

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“ (mainé–¢æ•°) ---
def main():
    st.set_page_config(layout="wide")
    config = load_config()

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– ---
    if 'processed_data' not in st.session_state:
        st.session_state['processed_data'] = None
        st.session_state['last_uploaded_filename'] = None
    if 'zero_cutoff_date' not in st.session_state:
         st.session_state['zero_cutoff_date'] = None
    if 'last_update_summary' not in st.session_state:
        st.session_state['last_update_summary'] = None

    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ --- #
    with st.sidebar:
        # st.image("logo.png", width=100)
        st.title("åˆ†æãƒ¡ãƒ‹ãƒ¥ãƒ¼")
        app_mode = st.radio(
            "å®Ÿè¡Œã—ãŸã„åˆ†æã‚’é¸æŠã—ã¦ãã ã•ã„:",
            ("äºˆæ¸¬ãƒ»æ¯”è¼ƒåˆ†æ", "ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»ä¿®æ­£"),
            key="app_mode_select"
        )
        st.markdown("---")
        st.header("ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type='csv')

    # --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿/å‡¦ç† --- #
    if uploaded_file is not None:
        if st.session_state.get('last_uploaded_filename') != uploaded_file.name:
             st.session_state['processed_data'] = None
             st.session_state['zero_cutoff_date'] = None
             st.session_state['last_update_summary'] = None
             st.session_state['last_uploaded_filename'] = uploaded_file.name
             st.info("æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚’å†å‡¦ç†ã—ã¾ã™ã€‚")

        if st.session_state['processed_data'] is None:
            with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†ä¸­..."):
                data_raw = load_data(uploaded_file)
                if data_raw is not None:
                    data_processed_base = preprocess_data(data_raw) # preprocessã®çµæœã‚’ä¸€æ™‚å¤‰æ•°ã«
                    if data_processed_base is not None and not data_processed_base.empty:
                         st.info("åˆæœŸãƒ©ã‚°ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
                         # â˜…â˜…â˜… recalculate_lag_feature ã®è¿”ã‚Šå€¤ã‚’ã‚¢ãƒ³ãƒ‘ãƒƒã‚¯ â˜…â˜…â˜…
                         data_processed_final, lag_info = recalculate_lag_feature(
                              df_processed=data_processed_base, # preprocesså¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™
                              lag_target_col=LAG_TARGET_COLUMN,
                              lag_days=LAG_DAYS,
                              booking_date_col=BOOKING_DATE_COLUMN,
                              group_cols=LAG_GROUP_COLS
                         )
                         # â˜…â˜…â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ã¯ DataFrame ã®ã¿ã‚’ä¿å­˜ â˜…â˜…â˜…
                         if data_processed_final is not None:
                             st.session_state['processed_data'] = data_processed_final
                             st.sidebar.success("ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†")
                         else:
                             # ãƒ©ã‚°è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ããŸå ´åˆ
                             st.error("ãƒ©ã‚°ç‰¹å¾´é‡ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                             st.session_state['processed_data'] = None # ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
                             st.stop()
                    else:
                         # preprocess_data ãŒç©ºã®DFãªã©ã‚’è¿”ã—ãŸå ´åˆ
                         st.error("ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                         st.session_state['processed_data'] = None
                         st.stop()
                else:
                    st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    st.session_state['processed_data'] = None
                    st.stop()

    # --- ãƒšãƒ¼ã‚¸è¡¨ç¤º --- #
    current_data = st.session_state.get('processed_data')
    if current_data is not None:
        if app_mode == "äºˆæ¸¬ãƒ»æ¯”è¼ƒåˆ†æ":
            render_prediction_analysis_page(current_data, config)
        elif app_mode == "ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»ä¿®æ­£":
            render_data_analysis_page(current_data)
        else:
            st.error("ç„¡åŠ¹ãªãƒ¢ãƒ¼ãƒ‰ãŒé¸æŠã•ã‚Œã¾ã—ãŸã€‚")
    elif uploaded_file is None:
         st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰åˆ†æå¯¾è±¡ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()